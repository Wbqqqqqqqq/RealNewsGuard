{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake news generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "file_path = \"/content/train.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=\"\"  # Replace with your own API key\n",
    ")\n",
    "def generate_fake_news(title):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"writer/palmyra-creative-122b\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please generate a continuous, well-structured news article about '{title}' while incorporating misleading elements. The article should read naturally as a typical news piece, without section headers, bullet points, conclusions, or disclaimers. The writing should flow smoothly, maintaining a journalistic tone without explicitly labeling misinformation.\"}],\n",
    "            temperature=0.5,\n",
    "            top_p=1,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        response_text = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        response_text = f\"Error: {str(e)}\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Processed: {title} (Time: {end_time - start_time:.2f}s)\")\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 10\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    results = list(executor.map(generate_fake_news, df['title']))\n",
    "\n",
    "df['generated_news'] = results\n",
    "\n",
    "df.to_csv(\"/content/generated_news_parallel_train2.csv\", index=False)\n",
    "print(\"Parallel Batch Processing Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real news generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=\"\"  # Replace with your own API key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_news(text):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"writer/palmyra-creative-122b\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please paraphrase the following news article with absolute factual fidelity: '{text}'. Maintain all original data points, names, dates, statistics and event sequences while altering sentence structures, vocabulary choices and phrasing patterns. Preserve the professional tone, contextual relationships and quantitative precision without introducing new information, omitting details, modifying causal connections or altering implications. The rewritten version must be linguistically distinct from the original yet retain identical factual content within Â±5% of the original word count, demonstrating human-level journalistic quality through concise rephrasing while strictly avoiding both factual distortion and unnecessary length variation. Maintain paragraph coherence without content duplication. Start directly with your generation.\"}],\n",
    "            temperature=0.5,\n",
    "            top_p=1,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        response_text = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        response_text = f\"Error: {str(e)}\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"(Time: {end_time - start_time:.2f}s)\")\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 10\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    results = list(executor.map(generate_real_news, train_df_real['text']))\n",
    "\n",
    "processed_df = pd.DataFrame({\n",
    "    \"text\": results,\n",
    "    \"generated\": 0\n",
    "})\n",
    "\n",
    "print(f\"Processed {len(processed_df)} records\")\n",
    "print(\"Sample output:\", processed_df.head(2))\n",
    "\n",
    "processed_df.to_csv(\"/content/AI_real_test_2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
