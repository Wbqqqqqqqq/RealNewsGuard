{
  "best_global_step": 7872,
  "best_metric": 0.03659016266465187,
  "best_model_checkpoint": "./output/checkpoint-7872",
  "epoch": 2.999142612174907,
  "eval_steps": 500,
  "global_step": 7872,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01905306277984186,
      "grad_norm": 6.2230024337768555,
      "learning_rate": 1.2690355329949238e-06,
      "loss": 0.6933,
      "step": 50
    },
    {
      "epoch": 0.03810612555968372,
      "grad_norm": 4.447866916656494,
      "learning_rate": 2.5380710659898476e-06,
      "loss": 0.6944,
      "step": 100
    },
    {
      "epoch": 0.05715918833952558,
      "grad_norm": 3.534815788269043,
      "learning_rate": 3.7817258883248736e-06,
      "loss": 0.6841,
      "step": 150
    },
    {
      "epoch": 0.07621225111936744,
      "grad_norm": 3.384044647216797,
      "learning_rate": 5.050761421319798e-06,
      "loss": 0.6776,
      "step": 200
    },
    {
      "epoch": 0.0952653138992093,
      "grad_norm": 2.1690444946289062,
      "learning_rate": 6.319796954314721e-06,
      "loss": 0.6608,
      "step": 250
    },
    {
      "epoch": 0.11431837667905116,
      "grad_norm": 3.3844008445739746,
      "learning_rate": 7.5888324873096455e-06,
      "loss": 0.6456,
      "step": 300
    },
    {
      "epoch": 0.13337143945889302,
      "grad_norm": 2.271270990371704,
      "learning_rate": 8.85786802030457e-06,
      "loss": 0.5772,
      "step": 350
    },
    {
      "epoch": 0.15242450223873488,
      "grad_norm": 1.6894649267196655,
      "learning_rate": 1.0101522842639596e-05,
      "loss": 0.4112,
      "step": 400
    },
    {
      "epoch": 0.17147756501857675,
      "grad_norm": 4.145639896392822,
      "learning_rate": 1.1345177664974621e-05,
      "loss": 0.2588,
      "step": 450
    },
    {
      "epoch": 0.1905306277984186,
      "grad_norm": 12.25007152557373,
      "learning_rate": 1.2614213197969544e-05,
      "loss": 0.1887,
      "step": 500
    },
    {
      "epoch": 0.20958369057826046,
      "grad_norm": 7.193542003631592,
      "learning_rate": 1.3883248730964469e-05,
      "loss": 0.1838,
      "step": 550
    },
    {
      "epoch": 0.22863675335810232,
      "grad_norm": 1.0126453638076782,
      "learning_rate": 1.5152284263959392e-05,
      "loss": 0.234,
      "step": 600
    },
    {
      "epoch": 0.24768981613794416,
      "grad_norm": 0.07082097977399826,
      "learning_rate": 1.6421319796954316e-05,
      "loss": 0.1468,
      "step": 650
    },
    {
      "epoch": 0.26674287891778603,
      "grad_norm": 0.050323378294706345,
      "learning_rate": 1.769035532994924e-05,
      "loss": 0.175,
      "step": 700
    },
    {
      "epoch": 0.2857959416976279,
      "grad_norm": 0.11534363776445389,
      "learning_rate": 1.8959390862944166e-05,
      "loss": 0.1721,
      "step": 750
    },
    {
      "epoch": 0.30484900447746976,
      "grad_norm": 1.0528558492660522,
      "learning_rate": 1.997459062676454e-05,
      "loss": 0.1376,
      "step": 800
    },
    {
      "epoch": 0.32390206725731163,
      "grad_norm": 0.19748790562152863,
      "learning_rate": 1.9833427442123097e-05,
      "loss": 0.2263,
      "step": 850
    },
    {
      "epoch": 0.3429551300371535,
      "grad_norm": 0.047096069902181625,
      "learning_rate": 1.969226425748165e-05,
      "loss": 0.1258,
      "step": 900
    },
    {
      "epoch": 0.3620081928169953,
      "grad_norm": 0.030907602980732918,
      "learning_rate": 1.9551101072840205e-05,
      "loss": 0.1358,
      "step": 950
    },
    {
      "epoch": 0.3810612555968372,
      "grad_norm": 0.20630402863025665,
      "learning_rate": 1.940993788819876e-05,
      "loss": 0.167,
      "step": 1000
    },
    {
      "epoch": 0.40011431837667905,
      "grad_norm": 0.08188112080097198,
      "learning_rate": 1.9268774703557312e-05,
      "loss": 0.0689,
      "step": 1050
    },
    {
      "epoch": 0.4191673811565209,
      "grad_norm": 0.7903481721878052,
      "learning_rate": 1.9130434782608697e-05,
      "loss": 0.1335,
      "step": 1100
    },
    {
      "epoch": 0.4382204439363628,
      "grad_norm": 0.0796995759010315,
      "learning_rate": 1.898927159796725e-05,
      "loss": 0.1782,
      "step": 1150
    },
    {
      "epoch": 0.45727350671620465,
      "grad_norm": 0.06624799221754074,
      "learning_rate": 1.8848108413325805e-05,
      "loss": 0.2417,
      "step": 1200
    },
    {
      "epoch": 0.4763265694960465,
      "grad_norm": 0.031900860369205475,
      "learning_rate": 1.8706945228684363e-05,
      "loss": 0.1188,
      "step": 1250
    },
    {
      "epoch": 0.4953796322758883,
      "grad_norm": 0.14155402779579163,
      "learning_rate": 1.8565782044042916e-05,
      "loss": 0.2124,
      "step": 1300
    },
    {
      "epoch": 0.5144326950557302,
      "grad_norm": 0.4011771082878113,
      "learning_rate": 1.8424618859401467e-05,
      "loss": 0.2204,
      "step": 1350
    },
    {
      "epoch": 0.5334857578355721,
      "grad_norm": 0.06705142557621002,
      "learning_rate": 1.8283455674760024e-05,
      "loss": 0.1459,
      "step": 1400
    },
    {
      "epoch": 0.5525388206154139,
      "grad_norm": 0.04445071890950203,
      "learning_rate": 1.8142292490118578e-05,
      "loss": 0.0978,
      "step": 1450
    },
    {
      "epoch": 0.5715918833952558,
      "grad_norm": 0.0025597931817173958,
      "learning_rate": 1.8001129305477136e-05,
      "loss": 0.1289,
      "step": 1500
    },
    {
      "epoch": 0.5906449461750977,
      "grad_norm": 0.003857370698824525,
      "learning_rate": 1.785996612083569e-05,
      "loss": 0.0888,
      "step": 1550
    },
    {
      "epoch": 0.6096980089549395,
      "grad_norm": 0.027877597138285637,
      "learning_rate": 1.771880293619424e-05,
      "loss": 0.0951,
      "step": 1600
    },
    {
      "epoch": 0.6287510717347814,
      "grad_norm": 0.01762615516781807,
      "learning_rate": 1.7577639751552797e-05,
      "loss": 0.1822,
      "step": 1650
    },
    {
      "epoch": 0.6478041345146233,
      "grad_norm": 0.005856914911419153,
      "learning_rate": 1.743647656691135e-05,
      "loss": 0.1203,
      "step": 1700
    },
    {
      "epoch": 0.6668571972944651,
      "grad_norm": 0.4333310127258301,
      "learning_rate": 1.7295313382269905e-05,
      "loss": 0.1935,
      "step": 1750
    },
    {
      "epoch": 0.685910260074307,
      "grad_norm": 0.01832028292119503,
      "learning_rate": 1.715415019762846e-05,
      "loss": 0.0937,
      "step": 1800
    },
    {
      "epoch": 0.7049633228541488,
      "grad_norm": 0.0013833357952535152,
      "learning_rate": 1.7012987012987013e-05,
      "loss": 0.1714,
      "step": 1850
    },
    {
      "epoch": 0.7240163856339906,
      "grad_norm": 0.3524288237094879,
      "learning_rate": 1.6871823828345567e-05,
      "loss": 0.0862,
      "step": 1900
    },
    {
      "epoch": 0.7430694484138325,
      "grad_norm": 0.026240503415465355,
      "learning_rate": 1.6730660643704124e-05,
      "loss": 0.0656,
      "step": 1950
    },
    {
      "epoch": 0.7621225111936744,
      "grad_norm": 4.097491264343262,
      "learning_rate": 1.6589497459062678e-05,
      "loss": 0.0757,
      "step": 2000
    },
    {
      "epoch": 0.7811755739735162,
      "grad_norm": 0.10400429368019104,
      "learning_rate": 1.6448334274421232e-05,
      "loss": 0.0892,
      "step": 2050
    },
    {
      "epoch": 0.8002286367533581,
      "grad_norm": 4.45898962020874,
      "learning_rate": 1.6307171089779786e-05,
      "loss": 0.1325,
      "step": 2100
    },
    {
      "epoch": 0.8192816995332,
      "grad_norm": 0.006414917763322592,
      "learning_rate": 1.616883116883117e-05,
      "loss": 0.086,
      "step": 2150
    },
    {
      "epoch": 0.8383347623130418,
      "grad_norm": 25.934799194335938,
      "learning_rate": 1.6027667984189725e-05,
      "loss": 0.0961,
      "step": 2200
    },
    {
      "epoch": 0.8573878250928837,
      "grad_norm": 0.0002512179489713162,
      "learning_rate": 1.588650479954828e-05,
      "loss": 0.1436,
      "step": 2250
    },
    {
      "epoch": 0.8764408878727256,
      "grad_norm": 0.009232464246451855,
      "learning_rate": 1.5745341614906833e-05,
      "loss": 0.0915,
      "step": 2300
    },
    {
      "epoch": 0.8954939506525674,
      "grad_norm": 0.0055809360928833485,
      "learning_rate": 1.560417843026539e-05,
      "loss": 0.0741,
      "step": 2350
    },
    {
      "epoch": 0.9145470134324093,
      "grad_norm": 0.02523825690150261,
      "learning_rate": 1.546301524562394e-05,
      "loss": 0.0278,
      "step": 2400
    },
    {
      "epoch": 0.9336000762122512,
      "grad_norm": 0.3879837095737457,
      "learning_rate": 1.5321852060982495e-05,
      "loss": 0.0283,
      "step": 2450
    },
    {
      "epoch": 0.952653138992093,
      "grad_norm": 0.0051398021169006824,
      "learning_rate": 1.5180688876341052e-05,
      "loss": 0.0651,
      "step": 2500
    },
    {
      "epoch": 0.9717062017719348,
      "grad_norm": 6.3601555824279785,
      "learning_rate": 1.5039525691699606e-05,
      "loss": 0.0845,
      "step": 2550
    },
    {
      "epoch": 0.9907592645517767,
      "grad_norm": 0.001954344566911459,
      "learning_rate": 1.489836250705816e-05,
      "loss": 0.0483,
      "step": 2600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9785775492716366,
      "eval_f1": 0.9770431588613406,
      "eval_loss": 0.09586851298809052,
      "eval_precision": 0.9620253164556962,
      "eval_recall": 0.9925373134328358,
      "eval_runtime": 189.5108,
      "eval_samples_per_second": 6.158,
      "eval_steps_per_second": 6.158,
      "step": 2625
    },
    {
      "epoch": 1.0095265313899209,
      "grad_norm": 0.007182941306382418,
      "learning_rate": 1.4757199322416715e-05,
      "loss": 0.0214,
      "step": 2650
    },
    {
      "epoch": 1.0285795941697629,
      "grad_norm": 0.003771384945139289,
      "learning_rate": 1.461603613777527e-05,
      "loss": 0.0784,
      "step": 2700
    },
    {
      "epoch": 1.0476326569496046,
      "grad_norm": 0.00931125320494175,
      "learning_rate": 1.4474872953133823e-05,
      "loss": 0.0912,
      "step": 2750
    },
    {
      "epoch": 1.0666857197294466,
      "grad_norm": 0.010214024223387241,
      "learning_rate": 1.4333709768492379e-05,
      "loss": 0.0968,
      "step": 2800
    },
    {
      "epoch": 1.0857387825092883,
      "grad_norm": 0.007582810707390308,
      "learning_rate": 1.4192546583850933e-05,
      "loss": 0.0629,
      "step": 2850
    },
    {
      "epoch": 1.1047918452891303,
      "grad_norm": 0.0006180241471156478,
      "learning_rate": 1.4051383399209488e-05,
      "loss": 0.0468,
      "step": 2900
    },
    {
      "epoch": 1.123844908068972,
      "grad_norm": 116.85899353027344,
      "learning_rate": 1.3910220214568042e-05,
      "loss": 0.1611,
      "step": 2950
    },
    {
      "epoch": 1.1428979708488138,
      "grad_norm": 0.18742388486862183,
      "learning_rate": 1.3769057029926596e-05,
      "loss": 0.0631,
      "step": 3000
    },
    {
      "epoch": 1.1619510336286558,
      "grad_norm": 2.565627098083496,
      "learning_rate": 1.3627893845285152e-05,
      "loss": 0.1384,
      "step": 3050
    },
    {
      "epoch": 1.1810040964084976,
      "grad_norm": 0.001994641264900565,
      "learning_rate": 1.3486730660643706e-05,
      "loss": 0.1443,
      "step": 3100
    },
    {
      "epoch": 1.2000571591883396,
      "grad_norm": 0.06609264761209488,
      "learning_rate": 1.334556747600226e-05,
      "loss": 0.1392,
      "step": 3150
    },
    {
      "epoch": 1.2191102219681813,
      "grad_norm": 0.043094560503959656,
      "learning_rate": 1.3204404291360815e-05,
      "loss": 0.0491,
      "step": 3200
    },
    {
      "epoch": 1.2381632847480233,
      "grad_norm": 0.0267195887863636,
      "learning_rate": 1.306324110671937e-05,
      "loss": 0.0663,
      "step": 3250
    },
    {
      "epoch": 1.257216347527865,
      "grad_norm": 0.22293484210968018,
      "learning_rate": 1.2922077922077922e-05,
      "loss": 0.061,
      "step": 3300
    },
    {
      "epoch": 1.276269410307707,
      "grad_norm": 0.00528601324185729,
      "learning_rate": 1.2780914737436479e-05,
      "loss": 0.0308,
      "step": 3350
    },
    {
      "epoch": 1.2953224730875488,
      "grad_norm": 0.0005469692987389863,
      "learning_rate": 1.2639751552795033e-05,
      "loss": 0.039,
      "step": 3400
    },
    {
      "epoch": 1.3143755358673908,
      "grad_norm": 0.0028794959653168917,
      "learning_rate": 1.2498588368153585e-05,
      "loss": 0.1106,
      "step": 3450
    },
    {
      "epoch": 1.3334285986472325,
      "grad_norm": 0.00034001210588030517,
      "learning_rate": 1.2357425183512142e-05,
      "loss": 0.0279,
      "step": 3500
    },
    {
      "epoch": 1.3524816614270745,
      "grad_norm": 0.23800572752952576,
      "learning_rate": 1.2216261998870695e-05,
      "loss": 0.0727,
      "step": 3550
    },
    {
      "epoch": 1.3715347242069162,
      "grad_norm": 11.043368339538574,
      "learning_rate": 1.2075098814229249e-05,
      "loss": 0.002,
      "step": 3600
    },
    {
      "epoch": 1.390587786986758,
      "grad_norm": 0.9329730272293091,
      "learning_rate": 1.1933935629587806e-05,
      "loss": 0.0184,
      "step": 3650
    },
    {
      "epoch": 1.4096408497666,
      "grad_norm": 0.0037554213777184486,
      "learning_rate": 1.1792772444946358e-05,
      "loss": 0.016,
      "step": 3700
    },
    {
      "epoch": 1.428693912546442,
      "grad_norm": NaN,
      "learning_rate": 1.1654432523997743e-05,
      "loss": 0.0279,
      "step": 3750
    },
    {
      "epoch": 1.4477469753262837,
      "grad_norm": 0.0009207192924804986,
      "learning_rate": 1.1513269339356297e-05,
      "loss": 0.0607,
      "step": 3800
    },
    {
      "epoch": 1.4668000381061255,
      "grad_norm": 0.000964316597674042,
      "learning_rate": 1.1372106154714851e-05,
      "loss": 0.0422,
      "step": 3850
    },
    {
      "epoch": 1.4858531008859674,
      "grad_norm": 0.002211085520684719,
      "learning_rate": 1.1230942970073407e-05,
      "loss": 0.1078,
      "step": 3900
    },
    {
      "epoch": 1.5049061636658094,
      "grad_norm": 0.003282453864812851,
      "learning_rate": 1.108977978543196e-05,
      "loss": 0.0017,
      "step": 3950
    },
    {
      "epoch": 1.5239592264456512,
      "grad_norm": 2.726630373217631e-05,
      "learning_rate": 1.0948616600790514e-05,
      "loss": 0.0026,
      "step": 4000
    },
    {
      "epoch": 1.543012289225493,
      "grad_norm": 0.007398216985166073,
      "learning_rate": 1.080745341614907e-05,
      "loss": 0.0386,
      "step": 4050
    },
    {
      "epoch": 1.5620653520053347,
      "grad_norm": 0.0019779999274760485,
      "learning_rate": 1.0666290231507624e-05,
      "loss": 0.0439,
      "step": 4100
    },
    {
      "epoch": 1.5811184147851767,
      "grad_norm": 0.0020111282356083393,
      "learning_rate": 1.052512704686618e-05,
      "loss": 0.0839,
      "step": 4150
    },
    {
      "epoch": 1.6001714775650187,
      "grad_norm": 0.0018924468895420432,
      "learning_rate": 1.0383963862224734e-05,
      "loss": 0.1044,
      "step": 4200
    },
    {
      "epoch": 1.6192245403448604,
      "grad_norm": 0.0015382412821054459,
      "learning_rate": 1.0242800677583287e-05,
      "loss": 0.0352,
      "step": 4250
    },
    {
      "epoch": 1.6382776031247022,
      "grad_norm": 0.0032675578258931637,
      "learning_rate": 1.0101637492941843e-05,
      "loss": 0.0722,
      "step": 4300
    },
    {
      "epoch": 1.6573306659045441,
      "grad_norm": 0.0001828083914006129,
      "learning_rate": 9.960474308300397e-06,
      "loss": 0.0261,
      "step": 4350
    },
    {
      "epoch": 1.6763837286843861,
      "grad_norm": 0.0015273139579221606,
      "learning_rate": 9.81931112365895e-06,
      "loss": 0.0529,
      "step": 4400
    },
    {
      "epoch": 1.6954367914642279,
      "grad_norm": 0.0007258486584760249,
      "learning_rate": 9.678147939017505e-06,
      "loss": 0.0916,
      "step": 4450
    },
    {
      "epoch": 1.7144898542440696,
      "grad_norm": 0.002001917688176036,
      "learning_rate": 9.53698475437606e-06,
      "loss": 0.0841,
      "step": 4500
    },
    {
      "epoch": 1.7335429170239116,
      "grad_norm": 0.0006258314242586493,
      "learning_rate": 9.395821569734614e-06,
      "loss": 0.0245,
      "step": 4550
    },
    {
      "epoch": 1.7525959798037536,
      "grad_norm": 0.12332828342914581,
      "learning_rate": 9.254658385093168e-06,
      "loss": 0.0375,
      "step": 4600
    },
    {
      "epoch": 1.7716490425835953,
      "grad_norm": 0.0013066785177215934,
      "learning_rate": 9.113495200451722e-06,
      "loss": 0.0386,
      "step": 4650
    },
    {
      "epoch": 1.790702105363437,
      "grad_norm": 0.0005904638092033565,
      "learning_rate": 8.972332015810278e-06,
      "loss": 0.0508,
      "step": 4700
    },
    {
      "epoch": 1.809755168143279,
      "grad_norm": 0.0002515803789719939,
      "learning_rate": 8.831168831168832e-06,
      "loss": 0.0374,
      "step": 4750
    },
    {
      "epoch": 1.8288082309231208,
      "grad_norm": 0.0199187733232975,
      "learning_rate": 8.690005646527386e-06,
      "loss": 0.0329,
      "step": 4800
    },
    {
      "epoch": 1.8478612937029628,
      "grad_norm": 0.011117634363472462,
      "learning_rate": 8.548842461885941e-06,
      "loss": 0.0151,
      "step": 4850
    },
    {
      "epoch": 1.8669143564828046,
      "grad_norm": 14.465463638305664,
      "learning_rate": 8.407679277244495e-06,
      "loss": 0.0279,
      "step": 4900
    },
    {
      "epoch": 1.8859674192626463,
      "grad_norm": 0.0027377838268876076,
      "learning_rate": 8.26651609260305e-06,
      "loss": 0.0001,
      "step": 4950
    },
    {
      "epoch": 1.9050204820424883,
      "grad_norm": 0.0008384587708860636,
      "learning_rate": 8.125352907961605e-06,
      "loss": 0.1177,
      "step": 5000
    },
    {
      "epoch": 1.9240735448223303,
      "grad_norm": 0.0006238986388780177,
      "learning_rate": 7.984189723320159e-06,
      "loss": 0.0564,
      "step": 5050
    },
    {
      "epoch": 1.943126607602172,
      "grad_norm": 0.009152580052614212,
      "learning_rate": 7.843026538678713e-06,
      "loss": 0.0005,
      "step": 5100
    },
    {
      "epoch": 1.9621796703820138,
      "grad_norm": 0.0004940318176522851,
      "learning_rate": 7.701863354037268e-06,
      "loss": 0.0308,
      "step": 5150
    },
    {
      "epoch": 1.9812327331618558,
      "grad_norm": 1.4116058349609375,
      "learning_rate": 7.560700169395822e-06,
      "loss": 0.0676,
      "step": 5200
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.731439604365733e-06,
      "learning_rate": 7.419536984754376e-06,
      "loss": 0.0075,
      "step": 5250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9837189374464439,
      "eval_f1": 0.9825206991720331,
      "eval_loss": 0.07718218117952347,
      "eval_precision": 0.969147005444646,
      "eval_recall": 0.996268656716418,
      "eval_runtime": 189.7517,
      "eval_samples_per_second": 6.15,
      "eval_steps_per_second": 6.15,
      "step": 5250
    },
    {
      "epoch": 2.0190530627798418,
      "grad_norm": 0.00018307552090846002,
      "learning_rate": 7.278373800112931e-06,
      "loss": 0.0271,
      "step": 5300
    },
    {
      "epoch": 2.0381061255596835,
      "grad_norm": 0.00040458253351971507,
      "learning_rate": 7.137210615471486e-06,
      "loss": 0.0048,
      "step": 5350
    },
    {
      "epoch": 2.0571591883395257,
      "grad_norm": 2.8979173293919303e-05,
      "learning_rate": 6.99604743083004e-06,
      "loss": 0.0263,
      "step": 5400
    },
    {
      "epoch": 2.0762122511193675,
      "grad_norm": 0.0009011005167849362,
      "learning_rate": 6.8548842461885945e-06,
      "loss": 0.0007,
      "step": 5450
    },
    {
      "epoch": 2.0952653138992092,
      "grad_norm": 0.0018843201687559485,
      "learning_rate": 6.713721061547149e-06,
      "loss": 0.0868,
      "step": 5500
    },
    {
      "epoch": 2.114318376679051,
      "grad_norm": 0.002583177527412772,
      "learning_rate": 6.572557876905703e-06,
      "loss": 0.0872,
      "step": 5550
    },
    {
      "epoch": 2.133371439458893,
      "grad_norm": 0.001306252903304994,
      "learning_rate": 6.431394692264258e-06,
      "loss": 0.0518,
      "step": 5600
    },
    {
      "epoch": 2.152424502238735,
      "grad_norm": 0.0019857636652886868,
      "learning_rate": 6.290231507622813e-06,
      "loss": 0.0001,
      "step": 5650
    },
    {
      "epoch": 2.1714775650185767,
      "grad_norm": 0.00038438994670286775,
      "learning_rate": 6.1490683229813675e-06,
      "loss": 0.0419,
      "step": 5700
    },
    {
      "epoch": 2.1905306277984185,
      "grad_norm": 0.0003614386369008571,
      "learning_rate": 6.007905138339921e-06,
      "loss": 0.0009,
      "step": 5750
    },
    {
      "epoch": 2.2095836905782607,
      "grad_norm": 96.62141418457031,
      "learning_rate": 5.866741953698476e-06,
      "loss": 0.0326,
      "step": 5800
    },
    {
      "epoch": 2.2286367533581024,
      "grad_norm": 0.03141392022371292,
      "learning_rate": 5.725578769057031e-06,
      "loss": 0.0826,
      "step": 5850
    },
    {
      "epoch": 2.247689816137944,
      "grad_norm": 0.013426966033875942,
      "learning_rate": 5.584415584415585e-06,
      "loss": 0.021,
      "step": 5900
    },
    {
      "epoch": 2.266742878917786,
      "grad_norm": 0.0008199618314392865,
      "learning_rate": 5.44325239977414e-06,
      "loss": 0.1096,
      "step": 5950
    },
    {
      "epoch": 2.2857959416976277,
      "grad_norm": 2.184552613471169e-05,
      "learning_rate": 5.3020892151326945e-06,
      "loss": 0.0101,
      "step": 6000
    },
    {
      "epoch": 2.30484900447747,
      "grad_norm": 0.000628334004431963,
      "learning_rate": 5.1609260304912475e-06,
      "loss": 0.064,
      "step": 6050
    },
    {
      "epoch": 2.3239020672573116,
      "grad_norm": 0.001287186867557466,
      "learning_rate": 5.019762845849802e-06,
      "loss": 0.0579,
      "step": 6100
    },
    {
      "epoch": 2.3429551300371534,
      "grad_norm": 0.0025160133372992277,
      "learning_rate": 4.878599661208357e-06,
      "loss": 0.0098,
      "step": 6150
    },
    {
      "epoch": 2.362008192816995,
      "grad_norm": 0.0017734771827235818,
      "learning_rate": 4.737436476566912e-06,
      "loss": 0.0695,
      "step": 6200
    },
    {
      "epoch": 2.3810612555968373,
      "grad_norm": 0.2485078126192093,
      "learning_rate": 4.596273291925466e-06,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 2.400114318376679,
      "grad_norm": 0.0024063149467110634,
      "learning_rate": 4.4551101072840206e-06,
      "loss": 0.019,
      "step": 6300
    },
    {
      "epoch": 2.419167381156521,
      "grad_norm": 0.0048764911480247974,
      "learning_rate": 4.313946922642575e-06,
      "loss": 0.0698,
      "step": 6350
    },
    {
      "epoch": 2.4382204439363626,
      "grad_norm": 0.0033333795145154,
      "learning_rate": 4.17278373800113e-06,
      "loss": 0.0323,
      "step": 6400
    },
    {
      "epoch": 2.457273506716205,
      "grad_norm": 0.0014993080403655767,
      "learning_rate": 4.031620553359684e-06,
      "loss": 0.0084,
      "step": 6450
    },
    {
      "epoch": 2.4763265694960466,
      "grad_norm": 0.0025278236716985703,
      "learning_rate": 3.890457368718239e-06,
      "loss": 0.0045,
      "step": 6500
    },
    {
      "epoch": 2.4953796322758883,
      "grad_norm": 0.0005536023527383804,
      "learning_rate": 3.749294184076793e-06,
      "loss": 0.0002,
      "step": 6550
    },
    {
      "epoch": 2.51443269505573,
      "grad_norm": 0.0004606763832271099,
      "learning_rate": 3.6081309994353475e-06,
      "loss": 0.0725,
      "step": 6600
    },
    {
      "epoch": 2.533485757835572,
      "grad_norm": 0.0005281007033772767,
      "learning_rate": 3.466967814793902e-06,
      "loss": 0.01,
      "step": 6650
    },
    {
      "epoch": 2.552538820615414,
      "grad_norm": 0.00011932932102354243,
      "learning_rate": 3.3258046301524567e-06,
      "loss": 0.0329,
      "step": 6700
    },
    {
      "epoch": 2.571591883395256,
      "grad_norm": 0.0015587422531098127,
      "learning_rate": 3.184641445511011e-06,
      "loss": 0.0007,
      "step": 6750
    },
    {
      "epoch": 2.5906449461750976,
      "grad_norm": 0.0019065819215029478,
      "learning_rate": 3.043478260869566e-06,
      "loss": 0.132,
      "step": 6800
    },
    {
      "epoch": 2.6096980089549398,
      "grad_norm": 0.0007613831548951566,
      "learning_rate": 2.9023150762281197e-06,
      "loss": 0.0327,
      "step": 6850
    },
    {
      "epoch": 2.6287510717347815,
      "grad_norm": 0.00037826254265382886,
      "learning_rate": 2.761151891586674e-06,
      "loss": 0.0003,
      "step": 6900
    },
    {
      "epoch": 2.6478041345146233,
      "grad_norm": 1.5049083231133409e-05,
      "learning_rate": 2.619988706945229e-06,
      "loss": 0.0433,
      "step": 6950
    },
    {
      "epoch": 2.666857197294465,
      "grad_norm": 0.0003911543171852827,
      "learning_rate": 2.478825522303783e-06,
      "loss": 0.0623,
      "step": 7000
    },
    {
      "epoch": 2.6859102600743068,
      "grad_norm": 0.001233321730978787,
      "learning_rate": 2.337662337662338e-06,
      "loss": 0.0749,
      "step": 7050
    },
    {
      "epoch": 2.704963322854149,
      "grad_norm": 0.0020392516162246466,
      "learning_rate": 2.1964991530208923e-06,
      "loss": 0.0048,
      "step": 7100
    },
    {
      "epoch": 2.7240163856339907,
      "grad_norm": 1.356454849243164,
      "learning_rate": 2.0553359683794467e-06,
      "loss": 0.0034,
      "step": 7150
    },
    {
      "epoch": 2.7430694484138325,
      "grad_norm": 0.029497044160962105,
      "learning_rate": 1.9141727837380015e-06,
      "loss": 0.1093,
      "step": 7200
    },
    {
      "epoch": 2.7621225111936742,
      "grad_norm": 0.03785679116845131,
      "learning_rate": 1.7730095990965556e-06,
      "loss": 0.0038,
      "step": 7250
    },
    {
      "epoch": 2.781175573973516,
      "grad_norm": 0.0007332407403737307,
      "learning_rate": 1.6318464144551102e-06,
      "loss": 0.0114,
      "step": 7300
    },
    {
      "epoch": 2.800228636753358,
      "grad_norm": 0.00038609164766967297,
      "learning_rate": 1.4906832298136647e-06,
      "loss": 0.0415,
      "step": 7350
    },
    {
      "epoch": 2.8192816995332,
      "grad_norm": 0.002200700342655182,
      "learning_rate": 1.3495200451722193e-06,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 2.8383347623130417,
      "grad_norm": 0.00015929197252262384,
      "learning_rate": 1.2083568605307737e-06,
      "loss": 0.0045,
      "step": 7450
    },
    {
      "epoch": 2.857387825092884,
      "grad_norm": 0.0011213432298973203,
      "learning_rate": 1.067193675889328e-06,
      "loss": 0.0001,
      "step": 7500
    },
    {
      "epoch": 2.8764408878727257,
      "grad_norm": 0.00442870520055294,
      "learning_rate": 9.260304912478827e-07,
      "loss": 0.0519,
      "step": 7550
    },
    {
      "epoch": 2.8954939506525674,
      "grad_norm": 2.3144379156292416e-05,
      "learning_rate": 7.848673066064371e-07,
      "loss": 0.0057,
      "step": 7600
    },
    {
      "epoch": 2.914547013432409,
      "grad_norm": 0.0008934197830967605,
      "learning_rate": 6.437041219649916e-07,
      "loss": 0.0114,
      "step": 7650
    },
    {
      "epoch": 2.933600076212251,
      "grad_norm": 0.002435309113934636,
      "learning_rate": 5.025409373235461e-07,
      "loss": 0.0002,
      "step": 7700
    },
    {
      "epoch": 2.952653138992093,
      "grad_norm": 0.07261350005865097,
      "learning_rate": 3.613777526821005e-07,
      "loss": 0.0071,
      "step": 7750
    },
    {
      "epoch": 2.971706201771935,
      "grad_norm": 0.0016927100950852036,
      "learning_rate": 2.2021456804065503e-07,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 2.9907592645517767,
      "grad_norm": 0.0016644764691591263,
      "learning_rate": 7.905138339920948e-08,
      "loss": 0.0089,
      "step": 7850
    },
    {
      "epoch": 2.999142612174907,
      "eval_accuracy": 0.9931448157669237,
      "eval_f1": 0.9925650557620818,
      "eval_loss": 0.03659016266465187,
      "eval_precision": 0.9888888888888889,
      "eval_recall": 0.996268656716418,
      "eval_runtime": 189.3166,
      "eval_samples_per_second": 6.164,
      "eval_steps_per_second": 6.164,
      "step": 7872
    }
  ],
  "logging_steps": 50,
  "max_steps": 7872,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
