{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4cd9ff0e35e9441699939d744c2b20a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5ca2d6f0ccf466090003da91f025ab5",
              "IPY_MODEL_46f66963b3894896bf2b86c406a6255c",
              "IPY_MODEL_ecd1d1b542144a0a83f160500a76bbb2"
            ],
            "layout": "IPY_MODEL_cf4e9d386e964dc7811c70b5d3c36025"
          }
        },
        "c5ca2d6f0ccf466090003da91f025ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df91285f112d43bb9f776e1d32fb6965",
            "placeholder": "​",
            "style": "IPY_MODEL_26551fbe239640c38862924c2c35c919",
            "value": "Map: 100%"
          }
        },
        "46f66963b3894896bf2b86c406a6255c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d13ab706d7435196cf820c2e4836ac",
            "max": 10497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fac3d799943d46d584c1b469143468a8",
            "value": 10497
          }
        },
        "ecd1d1b542144a0a83f160500a76bbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6379b1589bff4d81af21e596a2934e0c",
            "placeholder": "​",
            "style": "IPY_MODEL_1d8840c39aeb41bfb5f1ef8b691dadbc",
            "value": " 10497/10497 [00:39&lt;00:00, 264.96 examples/s]"
          }
        },
        "cf4e9d386e964dc7811c70b5d3c36025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df91285f112d43bb9f776e1d32fb6965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26551fbe239640c38862924c2c35c919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d13ab706d7435196cf820c2e4836ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac3d799943d46d584c1b469143468a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6379b1589bff4d81af21e596a2934e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8840c39aeb41bfb5f1ef8b691dadbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6093cf5f914405fb0aa9e05bf34cd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c3be06f26d64cf49f6dff6a1f478eed",
              "IPY_MODEL_df9594b095264232a52025053ffeb26e",
              "IPY_MODEL_69ee21912abe4f50859accaa61b6a4e5"
            ],
            "layout": "IPY_MODEL_4dbf8dcba7b24fecb2eeb8e35a4e3cd7"
          }
        },
        "7c3be06f26d64cf49f6dff6a1f478eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74ac61842cf4625a7690529e07d0fbe",
            "placeholder": "​",
            "style": "IPY_MODEL_148e250fa0e1452a831383b33fc9b1e9",
            "value": "Map: 100%"
          }
        },
        "df9594b095264232a52025053ffeb26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4cd9c9323604d0dbf2b8967a0eab712",
            "max": 1167,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73c9452eb34a42d58158527136653b7d",
            "value": 1167
          }
        },
        "69ee21912abe4f50859accaa61b6a4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5919fbaf5d9240d6a52684509bf71fc8",
            "placeholder": "​",
            "style": "IPY_MODEL_77f69147c59e4e8bad10f93a619720a1",
            "value": " 1167/1167 [00:04&lt;00:00, 272.57 examples/s]"
          }
        },
        "4dbf8dcba7b24fecb2eeb8e35a4e3cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74ac61842cf4625a7690529e07d0fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "148e250fa0e1452a831383b33fc9b1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4cd9c9323604d0dbf2b8967a0eab712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c9452eb34a42d58158527136653b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5919fbaf5d9240d6a52684509bf71fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f69147c59e4e8bad10f93a619720a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVXO2HWVbN0y",
        "outputId": "c3e18d53-3745-40f3-cf9f-5716bfd937bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374,
          "referenced_widgets": [
            "4cd9ff0e35e9441699939d744c2b20a8",
            "c5ca2d6f0ccf466090003da91f025ab5",
            "46f66963b3894896bf2b86c406a6255c",
            "ecd1d1b542144a0a83f160500a76bbb2",
            "cf4e9d386e964dc7811c70b5d3c36025",
            "df91285f112d43bb9f776e1d32fb6965",
            "26551fbe239640c38862924c2c35c919",
            "68d13ab706d7435196cf820c2e4836ac",
            "fac3d799943d46d584c1b469143468a8",
            "6379b1589bff4d81af21e596a2934e0c",
            "1d8840c39aeb41bfb5f1ef8b691dadbc",
            "f6093cf5f914405fb0aa9e05bf34cd13",
            "7c3be06f26d64cf49f6dff6a1f478eed",
            "df9594b095264232a52025053ffeb26e",
            "69ee21912abe4f50859accaa61b6a4e5",
            "4dbf8dcba7b24fecb2eeb8e35a4e3cd7",
            "d74ac61842cf4625a7690529e07d0fbe",
            "148e250fa0e1452a831383b33fc9b1e9",
            "c4cd9c9323604d0dbf2b8967a0eab712",
            "73c9452eb34a42d58158527136653b7d",
            "5919fbaf5d9240d6a52684509bf71fc8",
            "77f69147c59e4e8bad10f93a619720a1"
          ]
        },
        "id": "dG8I3Hu9O5S4",
        "outputId": "03833574-2954-474d-ec6d-2acd3549da41"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      index                                               text  generated  \\\n",
              "2576   2577  Canberra, Australia - In a surprise move, the ...          1   \n",
              "799     800  Wes Streeting has defended the growing use of ...          0   \n",
              "5135   5136  At about 3.15am on New Years Day, Caroline Mc...          0   \n",
              "1608   1609  INDIANAPOLIS, IN - The Indiana Fever's 2023 WN...          1   \n",
              "6454   6455  In a shocking turn of events, Detroit Lions wi...          1   \n",
              "\n",
              "                                                   clue  \\\n",
              "2576  ['Gov. Gavin Newsom of California signed legis...   \n",
              "799   ['The changes were intended to encourage more ...   \n",
              "5135  ['Cars sped past the 51-year-old man as he tru...   \n",
              "1608  ['Alarmed and angry, 80 experts published a ma...   \n",
              "6454  ['As he waited for a call from his agent in Se...   \n",
              "\n",
              "                                                   bm25  label  \n",
              "2576  [130.84947754501428, 130.84947754501428, 150.5...      1  \n",
              "799   [186.17401266066173, 173.02897845778216, 173.0...      0  \n",
              "5135  [309.77877873299434, 293.8986670266023, 283.18...      0  \n",
              "1608  [122.29280634066899, 132.45712275633673, 121.1...      1  \n",
              "6454  [107.4627853104494, 101.00252285268488, 121.72...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c752c19-45cb-4bcc-87f4-d4120159419b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "      <th>clue</th>\n",
              "      <th>bm25</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2576</th>\n",
              "      <td>2577</td>\n",
              "      <td>Canberra, Australia - In a surprise move, the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['Gov. Gavin Newsom of California signed legis...</td>\n",
              "      <td>[130.84947754501428, 130.84947754501428, 150.5...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>Wes Streeting has defended the growing use of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>['The changes were intended to encourage more ...</td>\n",
              "      <td>[186.17401266066173, 173.02897845778216, 173.0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5135</th>\n",
              "      <td>5136</td>\n",
              "      <td>At about 3.15am on New Years Day, Caroline Mc...</td>\n",
              "      <td>0</td>\n",
              "      <td>['Cars sped past the 51-year-old man as he tru...</td>\n",
              "      <td>[309.77877873299434, 293.8986670266023, 283.18...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608</th>\n",
              "      <td>1609</td>\n",
              "      <td>INDIANAPOLIS, IN - The Indiana Fever's 2023 WN...</td>\n",
              "      <td>1</td>\n",
              "      <td>['Alarmed and angry, 80 experts published a ma...</td>\n",
              "      <td>[122.29280634066899, 132.45712275633673, 121.1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6454</th>\n",
              "      <td>6455</td>\n",
              "      <td>In a shocking turn of events, Detroit Lions wi...</td>\n",
              "      <td>1</td>\n",
              "      <td>['As he waited for a call from his agent in Se...</td>\n",
              "      <td>[107.4627853104494, 101.00252285268488, 121.72...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c752c19-45cb-4bcc-87f4-d4120159419b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c752c19-45cb-4bcc-87f4-d4120159419b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c752c19-45cb-4bcc-87f4-d4120159419b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-698735f6-fa5e-4c36-913b-04fb6f1578a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-698735f6-fa5e-4c36-913b-04fb6f1578a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-698735f6-fa5e-4c36-913b-04fb6f1578a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    return batch\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2395,\n        \"min\": 800,\n        \"max\": 6455,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          800,\n          6455,\n          5136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Wes Streeting has defended the growing use of the private sector to help tackle long waiting lists for treatment but said providers must \\u0093pull their weight\\u0094 and not take resources away from the NHS. The health secretary, who has previously said \\u0093middle-class lefties\\u0094 risked putting ideological purity ahead of patient care, said he would be \\u0093entirely pragmatic\\u0094 about using spare capacity in the private sector. The government announced this week that private hospitals would provide NHS patients in England with as many as 1m extra appointments, scans and operations a year as part of the drive to end the backlog. \\u0093The Tories opened up in this country a two-tier system where those who could afford it would be paying to go private, being seen faster, and those who couldn\\u0092t were being left behind,\\u0094 Streeting said. \\u0093It is a point of principle to me that we end that two-tier system. Where there is spare capacity in the independent sector we will use it. We have agreed that we will work with them, and they will work with us to cut NHS waiting times.\\u0094 But he added: \\u0093At the same time the independent sector has to pull its weight. It\\u0092s got to be genuinely additional capacity. \\u0093I\\u0092m entirely pragmatic about this \\u0085 The independent healthcare sector isn\\u0092t going anywhere, and it can help us out of the hole we\\u0092re in. We would be mad not to.\\u0094 But the Centre for Health and the Public Interest, which tracks NHS privatisation, said Streeting was talking \\u0093utter nonsense\\u0094 about the private sector providing extra capacity because almost all the doctors it uses to perform operations are NHS staff. \\u0093Put simply, private hospitals are unable to deliver any operations without using NHS consultant surgeons or anaesthetists,\\u0094 it said. \\u0093Letting NHS consultants do the easy work in the private sector starves the NHS of both staff and income.\\u0094 Streeting, whose department received an extra \\u00a322bn at the budget, said he wanted to take a \\u0093big bet on tech\\u0094 at the spending review to help improve productivity in the NHS. But he added: \\u0093NHS staff say we love what you\\u0092re saying about AI, genomics, machine learning, but we would be grateful if we could just turn on a machine and it works in the morning.\\u0094 As part of the government\\u0092s 10-year NHS plan, to be published this spring, Streeting wants to shift focus from sickness to prevention, with the aim of shortening the amount of time people spend chronically unwell. Streeting said it was still his plan to \\u0093steamroll\\u0094 the food industry into promoting healthier options to tackle the obesity crisis, and he is working with the sector and other Whitehall departments on a plan to be published this year. He also said weight-loss drugs could not be a \\u0093get out of jail card\\u0094 for people wanting to lose a few stone, and in return patients must improve their diet and exercise. \\u0093The evidence is hugely encouraging, but it is complicated and nuanced,\\u0094 he added. He suggested the planned shift in healthcare from hospitals to the community would not result in local facilities being shut down. \\u0093The reassurance I can offer is that with our growing ageing society, hospitals are here to stay and have an important role to play.\\u0094 The NHS\\u0092s winter crisis continues to deepen, with more people in hospital being treated for flu and record numbers of long A&E ambulance handover delays. The intense pressure on the service amid the UK-wide cold snap has led to patients being managed in chairs \\u0093all day and all night\\u0094 and a hospital gym being turned into an overflow ward. An average of 5,408 people were in hospital in England with flu every day last week \\u0096 the second highest number since the Covid pandemic and up 21% on the 4,469 seen the week before. What Streeting called a \\u0093tidal wave of flu\\u0094 also led to more people receiving life-or-death care in intensive care (256) than a week earlier (211). NHS England\\u0092s latest \\u0093winter sitreps\\u0094 data, published on Thursday, showed that 19,554 people were stuck in the back of an ambulance last week for at least an hour before they were handed over to A&E staff because hospitals were so busy. They represented 21% of all handovers, up from 13% the week before. Doctors are alarmed at chaotic conditions in overcrowded hospitals putting patients at risk. Dr Mashkur Khan of the Royal College of Physicians said: \\u0093Our physiotherapy gym has now been taken over for extra bed spaces and the corridors are full to the brim. Patients are often managed in chairs all day and all night.\\u0094 Prof Sir Stephen Powis, NHS England\\u0092s national medical director, said hospitals were under \\u0093exceptional pressure\\u0094, with A&E staff so stretched that some were \\u0093saying that their days at work feel like some of the days we had during the height of the pandemic\\u0094.\",\n          \"In a shocking turn of events, Detroit Lions wide receiver Amon-Ra St. Brown took to social media to seemingly exact revenge on Dallas Cowboys cornerback Jourdan Lewis, sharing a screenshot of what appears to be a NSFW direct message exchange between the two players. The move came just hours after the Lions' 49-0 thrashing of the Cowboys at AT\\\\&T Stadium on Sunday, a game in which St. Brown hauled in 10 catches for 115 yards and a touchdown.  According to the screenshot, which was posted to St. Brown's Instagram story and has since been deleted, Lewis sent a series of expletive-laden messages to the Lions receiver, including one that read, \\\"You aint even top 3 on your own team.\\\" St. Brown, never one to back down from a challenge, responded with a string of laughing emojis and a simple, \\\"Lol what's good 27?\\\"  While it's unclear when the messages were sent, it's worth noting that St. Brown and Lewis have a history of trash talk dating back to their college days. The two players were on opposite sides of a heated rivalry between USC and Michigan during their respective collegiate careers, and it seems that old wounds may still be fresh.  When reached for comment, a Lions team spokesperson declined to address the situation, instead opting to focus on the team's upcoming matchup against the Green Bay Packers. \\\"We're just happy to come out with a big win on the road and we're already looking forward to next week,\\\" the spokesperson said.  Meanwhile, a Cowboys team source told ESPN that Lewis was \\\"furious\\\" about the situation, and that the team was \\\"looking into it.\\\" \\\"Jourdan's a competitor and he wears his heart on his sleeve, but that's no excuse for that kind of language,\\\" the source said.  The incident is just the latest in a string of off-field controversies to surround St. Brown this season. In Week 1, the receiver was involved in a heated exchange with Los Angeles Rams cornerback Jalen Ramsey, and in Week 3, he was fined $10,000 by the NFL for unsportsmanlike conduct after making a lewd gesture towards a group of Minnesota Vikings fans.  Despite the off-field drama, St. Brown has been on fire on the field, hauling in 34 catches for 443 yards and 3 touchdowns through the Lions' first five games. The team will look to ride that momentum into next Sunday's matchup against the Packers, which is set to kick off at 1:00 PM ET from Ford Field.\",\n          \"At about 3.15am on New Year\\u0092s Day, Caroline McClymont looked out of her bedroom window at the Sankey brook over the road. It looked a bit fuller than usual \\u0096 to be expected, given the rain. \\u0093But there was nothing out of the ordinary,\\u0094 McClymont said. \\u0093There was no indication it was going to flood.\\u0094 Within an hour, the whole street was under water. The home McClymont, a science lecturer, has owned with her husband Alan, a technician, for 31 years was filled with dirty water, higher than the kitchen countertops. It covered the sofas, washing machine, Christmas tree, everything on the ground floor. The neighbour\\u0092s car was submerged. \\u0093Everything is destroyed. Nothing could be saved,\\u0094 McClymont said. \\u0093It\\u0092ll take six, seven months to get right again. \\u0093It\\u0092s all those memories that you\\u0092ve collected for years and little, little things that you can\\u0092t replace. Nothing can be saved because it\\u0092s not just canal water, it\\u0092s sewage from the drains.\\u0094 The damage caused by the water \\u0096 which has now receded \\u0096 is extreme. But for McClymont and her neighbours the flooding was no surprise. For years they have been begging the local council and Environment Agency to improve defences in the area after a string of similar incidents, including floods in 2000, 2012, 2015 and a less severe one last month. Their street in Haydock, St Helens, Merseyside, sits on low ground at the intersection of several waterways, the Sankey canal and two brooks, making it vulnerable. The issues were compounded during the new year flood when a water pump installed to quickly drain the area failed to activate \\u0096 apparently due to a power outage at a United Utilities site, caused when the brook burst its banks. But McClymont, who chairs the Blackbrook Flood Group, and runs a WhatsApp group with flood alerts for residents, says simple things that could lessen the risk have been neglected, including maintenance and dredging. Pipes to divert water when flows are high are left to fill with leaves, which she and Alan often rake away themselves whenever there\\u0092s heavy rain. A promised tele\\u00admetry system to monitor water levels also has not been activated, with residents told it is still being calibrated. \\u0093We\\u0092ve been fighting this for years,\\u0094 she said. \\u0093People say, \\u0091Why don\\u0092t you just move?\\u0092 but I can\\u0092t afford to buy another house. No one\\u0092s going to buy it now it\\u0092s flooded. So we\\u0092re stuck here.\\u0094 A few doors down, Chris Moles, 60, a microbiologist who moved in last year, estimates she and her husband, hotel manager Adrian, 53, have lost possessions worth \\u00a330,000, including a car, kitchen goods, and a Macbook \\u0096 as well as her microscope, fossils, rare books and an autograph from Leonard Nimoy, Mr Spock. \\u0093Obviously we\\u0092re alive. Everybody survived. But this is the worst it\\u0092s ever been,\\u0094 she said. The couple also lost artwork by Adrian\\u0092s son Adam, who died with Addison\\u0092s disease five years ago, aged 15. \\u0093We would\\u0092ve lost everything else if we could\\u0092ve just kept that drawing he did,\\u0094 Moles said. Before they bought the house \\u0096 their first \\u0096 in April, they say they were promised that defences had been put in place and that the chance of flooding was \\u0093very slim\\u0094. \\u0093We were told they\\u0092d done this, that and the other, and that there was a very slim chance that it would flood. That didn\\u0092t turn out to be true,\\u0094 she said. \\u0093It\\u0092s heartbreaking. I can understand there\\u0092s tonnes of people out there that need help. There\\u0092s loads of places flooding. But when this has happened four, five times, you\\u0092d think by now they\\u0092d have done something. You pay council tax and you trust the people in charge to act in your best interests. And that\\u0092s just not happened. We literally have been left behind.\\u0094 Seven miles away in Bewsey, Warrington, residents near another stretch of the Sankey canal faced a similar fate. Vulnerable people living in supported housing were among the worst hit after a brook connected to the canal overflowed. Among them was Barbara Gee, 61, who was cooking a New Year\\u0092s Day meal for her husband of 42 years, Alan, 67, when the water began pouring in. At about 3.30pm she had looked out the front window of her bungalow and seen the playing fields and road submerged. It appeared to be encroaching. But after a flood in 2021, the couple had been given a flood barrier by the housing association that manages the property to attach to their front door. Gee sent her daughter Liz a photo of the flooding, which had reached her doorstep. \\u0093OMG,\\u0094 Liz replied, asking if the flood barrier was working. \\u0093For now,\\u0094 Gee wrote back. But within half an hour the defence had been overwhelmed. She said water poured in not just through the front door but into every room: it spurted up through the drains in their bathroom, up through the toilet, and seeped in through the walls. \\u0093I was crying. Just burst into tears,\\u0094 she said. The couple have lost almost everything they own. On Friday, three days after the flood, their possessions were piled on their front lawn, contaminated or destroyed. The heap included a sofa, kitchen appliances, carpets and Gee\\u0092s electric scooter. An alert system used to call for help in an emergency was broken. Their clothes and shoes were drenched. \\u0093We lost four bin bags\\u0092 worth of food from the freezer and everything is wet through,\\u0094 Gee said. They are stoic and grateful: they have family who can support them. And they are thankful to the local Warrington council for helping house them at a hotel while they try to sort things out. But they feel they and their neighbours have been neglected. \\u0093The flood defences didn\\u0092t work. It needs to be a lot safer. We\\u0092ve had help with housing and food; I can\\u0092t knock them for that. They have been so good like that. They have tried to put up flood barriers, which haven\\u0092t worked. They have most probably thought that would help. But what\\u0092s the use having flood barriers if it\\u0092s going to come in through the walls?\\u0094 Gee said. The clean-up will take months, with no money to help from contents insurance, which they could not afford to pay for \\u0093because of the cost of living\\u0094, and because after the last flood, \\u0093it is too expensive\\u0094. Their neighbour Jeffrey Frain, 78, a lollipop man and former bus driver, whose possessions are piled outside his bungalow too, is in the same boat. \\u0093I believe it\\u0092s very expensive to get insurance here \\u0085 When it flooded last time it brought the premiums up,\\u0094 he said. He said flood barriers provided by the housing association were a \\u0093waste of space\\u0094. \\u0093I put the flood barriers up but the water came in within minutes. I tried to brush it out but then I gave up,\\u0094 he said. \\u0093It\\u0092s disastrous for me. I have a dog. I live on my own. I\\u0092m staying with one of my sons but I feel like a burden and I don\\u0092t like imposing.\\u0094 He added: \\u0093The flooding has been going on for years. It\\u0092s an ongoing thing and I don\\u0092t think they\\u0092ve done enough.\\u0094 Back in Haydock, the clean-up mission is in full swing. On Friday, volunteers came armed with cleaning supplies to scrub bathrooms and bundle destroyed possessions into skips. The McClymonts \\u0096 one of few households on the road that were able to secure insurance \\u0096 have to keep everything until the assessors come out, so their driveway is covered with 20 black bags. The worst thing, says Amy, 25, who lives with her stepdad Richard Coulburn and mother Joanne a few doors down, is that it feels this could have been prevented. \\u0093It\\u0092s traumatic,\\u0094 says Amy. \\u0093We\\u0092re going to be traumatised every time it rains. We need this not to be a worry any more. I think it\\u0092s ridiculous. It happened like 10 years ago. How is it able to happen again?\\u0094 An Environment Agency spokesperson said: \\u0093Protecting communities is our top priority ... Environment Agency teams have been working around the clock over the new year, operating flood defences, issuing flood warnings and supporting those communities affected. \\u0093More broadly, we are delivering a long-term funding programme of flood defences, investing over \\u00a31bn this year to scale up national resilience through building new and improving existing flood defences.\\u0094 Adam Hug, the Local Government Association\\u0092s environment spokesperson, said: \\u0093While councils will always do their best to ensure their areas are as resilient as possible, and when responding to severe weather prioritise efforts to ensure residents are safe, financial pressures on local government have an impact on their ability to address issues such as flooding as much as they\\u0092d like ... \\u0093The nation is not sufficiently prepared [for the impacts of the changing climate], and central government must prioritise its work with local government to close this gap.\\u0094 Of the flooding in Haydock, United Utilities said: \\u0093A pumping station was flooded when the local brook burst its banks. This caused a power outage at our site. We have deployed a tanker to the area to manage our operations.\\u0094\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['The changes were intended to encourage more competition in health provision but were criticized for creating a fragmented and complex structure.\\\\n\\\\nMr. Darzi, who was once a Labour Party member but left because of its handling of antisemitism allegations under the former leader Jeremy Corbyn, pointed to the inadequacy of government spending increases for the N.H.S. that, for most of the 2010s, were limited to 1 percent compared with a decades-long average of 3.4 percent.\\\\n\\\\nChronic problems that had built up in the health service over years became acute when Covid-19 hit, and the N.H.S. entered the pandemic with fewer available beds and fewer staff than most other high-income health systems, the report said.\\\\n\\\\nHospitals delayed, canceled or postponed more routine care during that period than any comparable health system did.\\\\n\\\\nThe result was longer waits for treatment. Lines at emergency rooms more than doubled, from an average of just under 40 people on a typical evening in April 2009 to over 100 in April this year.'\\n 'The report, written by Ara Darzi, a surgeon and member of the House of Lords, said that during the 2010s, when a Conservative-led government embarked on a stringent austerity program, the N.H.S. was \\u201cstarved of capital,\\u201d leading it to fall behind other countries in terms of investing in diagnostic equipment, technology and buildings.\\\\n\\\\nHis findings will not surprise Britons, whose satisfaction in the health service is \\u201cat its lowest ever,\\u201d the report said, having peaked in 2009. Still, even Professor Darzi, who has spent three decades in the N.H.S., said that he was \\u201cshocked\\u201d by what he discovered and laid the blame for the problems on successive Conservative governments that held power for 14 years.\\\\n\\\\nMr. Starmer described the findings as \\u201cunforgivable\\u201d in comments released before a speech on Thursday, in which he plans to argue that the health service must \\u201creform or die.\\u201d\\\\n\\\\n\\u201cPeople have every right to be angry,\\u201d he said. \\u201cIt\\u2019s not just because the N.H.S. is so personal to all of us \\u2014 it\\u2019s because some of these failings are life and death.\\u201d\\\\n\\\\nPaid for through general taxation and payroll deductions, medical treatment in Britain is delivered to patients without money changing hands, with a few exceptions such as dentistry and prescription medication.'\\n 'The report, written by Ara Darzi, a surgeon and member of the House of Lords, said that during the 2010s, when a Conservative-led government embarked on a stringent austerity program, the N.H.S. was \\u201cstarved of capital,\\u201d leading it to fall behind other countries in terms of investing in diagnostic equipment, technology and buildings.\\\\n\\\\nHis findings will not surprise Britons, whose satisfaction in the health service is \\u201cat its lowest ever,\\u201d the report said, having peaked in 2009. Still, even Professor Darzi, who has spent three decades in the N.H.S., said that he was \\u201cshocked\\u201d by what he discovered and laid the blame for the problems on successive Conservative governments that held power for 14 years.\\\\n\\\\nMr. Starmer described the findings as \\u201cunforgivable\\u201d in comments released before a speech on Thursday, in which he plans to argue that the health service must \\u201creform or die.\\u201d\\\\n\\\\n\\u201cPeople have every right to be angry,\\u201d he said. \\u201cIt\\u2019s not just because the N.H.S. is so personal to all of us \\u2014 it\\u2019s because some of these failings are life and death.\\u201d\\\\n\\\\nPaid for through general taxation and payroll deductions, medical treatment in Britain is delivered to patients without money changing hands, with a few exceptions such as dentistry and prescription medication.'\\n '\\u201cPeople have every right to be angry,\\u201d he said. \\u201cIt\\u2019s not just because the N.H.S. is so personal to all of us \\u2014 it\\u2019s because some of these failings are life and death.\\u201d\\\\n\\\\nPaid for through general taxation and payroll deductions, medical treatment in Britain is delivered to patients without money changing hands, with a few exceptions such as dentistry and prescription medication.\\\\n\\\\nBut in his speech on Thursday, Mr. Starmer is expected to prepare Britons for a long wait before their health care system is restored. That echoes a warning he made last month that, because of the scale of the challenge he inherited in restoring the economy and public services, circumstances \\u201cwill get worse before they get better.\\u201d\\\\n\\\\nMr. Starmer said his government would focus on digitizing the N.H.S., moving care from overburdened hospitals to other settings in the community and investing in preventive health care.\\\\n\\\\nMr. Darzi\\u2019s report pointed out that the failure to invest in the N.H.S. had coincided with rising demand because of Britain\\u2019s aging population and surging levels of long-term sickness.\\\\n\\\\nAmong the consequences: Long waits for treatment in emergency rooms are estimated to have caused an additional 14,000 deaths each year. And outcomes for cancer patients lag behind those of comparable countries, with \\u201cappreciably higher\\u201d mortality rates in Britain than in many European nations, the report said.'\\n 'Doctors and nurses have struggled to care for the nearly 70 million people in the United Kingdom after years of challenges, including chronic underinvestment in the N.H.S. under Conservative-led governments that held power from 2010 to 2024.\\\\n\\\\n\\u201cThis must be a watershed moment, a line in the sand,\\u201d Dr. Adrian Boyle, the president of the Royal College of Emergency Medicine, said in a statement.\\\\n\\\\nDr. Boyle was one of several leading British physicians to express solidarity with the nurses. He called the testimonies \\u201charrowing.\\u201d\\\\n\\\\n\\u201cThe toll it is taking on staff is clear,\\u201d he added. \\u201cPeople in tears, frustrated, angry and in some cases even giving up their careers because they cannot face going to work every day not being able to provide the level of care they want to.\\u201d\\\\n\\\\nThe nurses\\u2019 report, which describes a crisis of \\u201ccorridor care,\\u201d comes just months after another blockbuster report found that the N.H.S. was in \\u201ccritical\\u201d condition.\\\\n\\\\nPatients routinely waited hours for treatment as doctors tried to work without adequate medical equipment or sufficient space in hospitals, according to that report, which was commissioned by the government and published in September. It found that national satisfaction with the beleaguered health service was \\u201cat its lowest ever.\\u201d'\\n 'Under the British system, the scope of the proposed law extends only to England and Wales. A push for similar legislation is underway in the Scottish Parliament.\\\\n\\\\nPolls suggest a clear majority of Britons support the principle of assisted dying as long as conditions are attached, with 65 percent in favor and 13 percent opposed, according to one recent survey.\\\\n\\\\nMany faith leaders, however, expressed their opposition to the move and, ahead of the vote, two senior cabinet ministers, the justice secretary, Shabana Mahmood, and the health secretary, Wes Streeting, also spoke out against the measure.\\\\n\\\\nMr. Streeting argued that training staff to deal with assisted dying would add costs to the country\\u2019s National Health Service. He also pointed to the uneven availability of palliative care in Britain, warning that some patients might feel that they effectively had no alternative but to opt for assisted dying.\\\\n\\\\nAfter Friday\\u2019s vote, the foreign secretary, David Lammy, said that he had opposed the measure because of his mother\\u2019s end-of-life experience. \\u201cLike millions of working class people, her final diagnosis filled her not with fear of death but a fear of being a burden to her family,\\u201d he wrote in a letter to his constituents.'\\n 'In essence, employment levels are high, but those looking for work are having a harder time. Subdued hiring and subdued firings is an odd limbo to be in. Typically, once unemployment ticks up from its low point during a cycle, it does not gently wiggle sideways near that level; it tends to spike before easing again.\\\\n\\\\nAsked whether unemployment would hit 5 percent sooner than reverting to 4 percent \\u2014 as precedent and economic theory would suggest \\u2014 Peter Williams, an economist and managing director at 22V Research, an investment strategy and quantitative analysis firm, said, \\u201cI\\u2019m quite torn.\\u201d\\\\n\\\\nDespite a \\u201crobust starting point\\u201d for the year and the Fed\\u2019s ability to cut interest rates further if more trouble appears, he said, bad omens linger, like the moribund housing market.\\\\n\\\\n\\u201cBut there\\u2019s also just so few vulnerabilities in the economy right now that it\\u2019s hard to see how falling down two steps is enough to really wreck things,\\u201d he added.'\\n 'England\\u2019s National Health Service, one of the country\\u2019s most revered institutions, is in \\u201ccritical\\u201d condition, according to a government-commissioned report that cited long waits for treatment, crumbling hospitals, mental health patients in \\u201cvermin-infested cells\\u201d and far fewer M.R.I. scanners than in comparable countries.\\\\n\\\\nThe hard-hitting review, published late on Wednesday, was commissioned by Britain\\u2019s new prime minister, Keir Starmer, after he won the general election. The dire state of the N.H.S. was a key reason many people voted for his Labour Party in July, according to polls.\\\\n\\\\nBut the report underscores the scale of the challenge the government faces to revive a health care system that is in a spiral of decline after years of underinvestment and administrative meddling and is still suffering the aftershocks of the pandemic.\\\\n\\\\nMr. Starmer said in comments his office released on Wednesday that he was working on a 10-year plan that could amount to the \\u201cbiggest reimagining of our N.H.S.\\u201d since its creation in 1948.\\\\n\\\\nThe report, written by Ara Darzi, a surgeon and member of the House of Lords, said that during the 2010s, when a Conservative-led government embarked on a stringent austerity program, the N.H.S. was \\u201cstarved of capital,\\u201d leading it to fall behind other countries in terms of investing in diagnostic equipment, technology and buildings.'\\n '\\u201cIt\\u2019s hugely disappointing,\\u201d said Dr. Thomas Foltynie of University College London, who led the trial. \\u201cWe were expecting we would come through and we would get a positive result.\\u201d\\\\n\\\\nParkinson\\u2019s experts shared his sentiment.\\\\n\\\\n\\u201cThis is a sobering moment,\\u201d said Dr. Michael S. Okun, a Parkinson\\u2019s disease expert at the University of Florida and the national medical adviser for the Parkinson\\u2019s Foundation. \\u201cThis is a really well done study and it came up empty-handed.\\u201d\\\\n\\\\nThe finding may have implications for researchers who are asking if the newer GLP-1 drugs could help slow the course of Alzheimer\\u2019s or could prevent the disease.\\\\n\\\\nThe new study involved 194 people with Parkinson\\u2019s disease treated at six research hospitals in the U.K. The patients were randomly assigned to inject themselves once a week for 96 weeks with exenatide, a type 2 diabetes treatment made by AstraZeneca and sold under the brand name Byetta, or with a placebo. The trial was funded by Britain\\u2019s National Institute for Health and Care Research with support for substudies from the charity Cure Parkinson\\u2019s and the Van Andel Institute.\\\\n\\\\nThe drug is in the same class as Ozempic and Wegovy and, like them, lowers blood sugar levels. All are so-called GLP-1 receptor agonists, commonly called GLP-1s. Exenatide is not as powerful in eliciting weight loss as the newer drugs, but experts say there is no reason to believe that the more recent drugs would perform differently in studies of brain disease.'\\n 'On Monday, the Trump administration ordered health organizations in other countries to immediately stop distributing H.I.V. medications purchased with U.S. aid. The directive stemmed from a freeze \\u2014 which may become permanent \\u2014 in the activities of PEPFAR, a $7.5 billion program overseen by the State Department.\\\\n\\\\nSince it started in 2003, PEPFAR is estimated to have saved more than 25 million lives; more than 5.5 million children have been born free of H.I.V. who otherwise would have been infected.\\\\n\\\\nIn South Africa alone, PEPFAR\\u2019s shutdown would add more than a half million new H.I.V. infections and more than 600,000 related deaths over the next decade, according to one estimate.\\\\n\\\\nThe organization employs 270,000 doctors, nurses, pharmacists and other health workers. They had been told not to report to work or to serve patients.\\\\n\\\\nDr. Abdool Karim said countries should stop relying on PEPFAR and support their own citizens, a goal that the program\\u2019s staff and partners had been working toward. But ideally that shift would happen gradually, over years during which PEPFAR would train local health workers and prepare them for the transition, he said.\\\\n\\\\n\\u201cThis is not a bad opportunity for countries to take greater responsibility,\\u201d he said. \\u201cBut I think they can\\u2019t do it if it\\u2019s done in this kind of haphazard and unplanned way.\\u201d\\\\n\\\\nHere\\u2019s what he and others expect from PEPFAR\\u2019s unexpected pause.\\\\n\\\\nSudden stops to H.I.V. treatment can quickly turn dangerous.']\",\n          \"['As he waited for a call from his agent in September, Isaac Rochell, a professional football player looking for a team, watched the National Football League\\u2019s opening weekend games on television with his infant daughter. His wife needed a baby sitter.\\\\nAllison Kucharczyk, Rochell\\u2019s wife and an online influencer with more than three million TikTok followers, was closer to the field than he was thanks to a partnership with NBC Sports. She was crisscrossing continents on a private jet with other content creators to document a weekend of rowdy tailgates, concession food and stadium environments at N.F.L. games in Kansas City, Mo.; S\\u00e3o Paulo, Brazil; and Detroit.\\\\nBy documenting her lifestyle as a professional athlete\\u2019s wife, Kucharczyk has become more famous than Rochell, who reached the highest level of his sport but never became a household name. When together in public, Rochell said, people sometimes ask for Kucharczyk\\u2019s autograph instead of his.\\\\nAs the N.F.L. and its media partners court more female viewers, they are increasingly aligning with the wives and girlfriends of players. (The partnership of Travis Kelce and Taylor Swift was inescapable last season.) They hope that prospective fans who are uninterested in sports jargon and players battering one another on the field might instead respond to clothing ensembles and glamorized experiences in luxury suites.\\\\nThank you for your patience while we verify access'\\n 'It was late Sunday evening at Pullman Yards, a former fertilizer plant and industrial complex that now serves as an entertainment venue on the east side of Atlanta, and the YouTuber Kyle Forgeard\\u2019s path to victory in a glammed-up fantasy football championship was narrowing.\\\\nRubi Rose, a rapper and internet personality from Lexington, Ky., had established a commanding lead as the Bengals-Chargers game barreled toward halftime, and Mr. Forgeard\\u2019s chances of winning back-to-back championships, which seemed good earlier that day, were fading.\\\\nMr. Forgeard, who is known for his pranks and podcasts as part of the group the Nelk Boys, sat on a plush black leather sofa watching an enormous television screen, his eyes fixed in earnest concentration, as people buzzed around him. Nearby was Arthur Kulik, known as Jimmy Gambles, who is Mr. Forgeard\\u2019s right-hand man and his closest adviser in the game.\\\\n\\u201cI don\\u2019t know about the other teams, but this is very serious to me,\\u201d Mr. Forgeard said. \\u201cI want to repeat. I\\u2019m trying to win.\\u201d'\\n 'A traffic stop that led to Tyreek Hill, a wide receiver for the Miami Dolphins, being handcuffed outside the team\\u2019s stadium on Sunday escalated quickly after a police officer knocked on the player\\u2019s car window and he objected, body camera footage of the incident shows.\\\\nThe Miami-Dade Police Department released the video on Monday evening after initially delaying its release pending an internal affairs investigation into the officer\\u2019s actions. The investigation is ongoing.\\\\nMr. Hill\\u2019s brief detention \\u2014 he was later released and went on to score a touchdown in the Dolphins\\u2019 season opener on Sunday against the Jacksonville Jaguars \\u2014 prompted concerns about police use of force. The president of a local police union countered those accusations by saying that the officers had followed policy after Mr. Hill was being \\u201cuncooperative.\\u201d\\\\nOne of the officers involved was temporarily reassigned to administrative duties. On Tuesday, the police department identified the officer as Danny Torres, a 27-year police veteran. A lawyer for Officer Torres said that he should be reinstated to regular duties, while a lawyer for Mr. Hill called for the officer to be fired, The Miami Herald reported.\\\\nOn Wednesday, Mr. Hill told reporters at a team practice that he could have acted \\u201ca bit differently\\u201d on Sunday, including by leaving his car window down when the police told him to.\\\\n\\u201cI will say I could have been better,\\u201d he said. \\u201cNow, does that give them the right to literally beat the dog out of me? Absolutely not'\\n 'Shannon Sharpe won three Super Bowls in a Hall of Fame career and once recorded 214 receiving yards in a game, the most ever by a National Football League tight end. Another crowning achievement came long after he was outmuscling bulky defenders, when he convinced a 5-foot-5 comedian to open up while sipping cognac on a brown leather sofa.\\\\nWhen that comedian and actor, Katt Williams, aired his grievances against prominent Black celebrities, including Sean Combs and Kevin Hart, it instantly turned Sharpe\\u2019s podcast \\u201cClub Shay Shay\\u201d into a must-stop destination in Hollywood and beyond. In the months after the episode aired in January 2024, Sharpe secured interviews with the rapper Megan Thee Stallion and the Democratic presidential candidate Kamala Harris.\\\\n\\u201c\\u2018Club Shay Shay\\u2019 has become the modern-day talk show,\\u201d said Lillian Xu, a top podcast executive for Vox Media, which produces a handful of rival series.'\\n \\\". With no tournaments to contest, Roger Federer hit tennis balls against a wall \\u2026 in a snowstorm. Novak Djokovic used a frying pan instead of a racket.\\\\nYou enjoy watching them play five-on-five basketball, so maybe you\\u2019d like seeing N.B.A. and W.N.B.A. stars play HORSE from their own homes? Well, it was a good idea. Shaky video and sound and an absence of trick shots meant the show got mostly bad reviews.\\\\nThe virus didn\\u2019t just postpone leagues, it killed one of them. The XFL, which had begun its first football season in 19 years in February, filed for bankruptcy.\\\\nVon Miller, the Broncos' star linebacker, revealed he had the coronavirus, one of the most prominent athletes to do so.\\\\nDarts stars were able to set up competitions, with each entrant throwing at his or her own home. Unfortunately, at least one player had to pull out \\u2026 because of bad Wi-Fi.\\\\nWith almost no live sports to watch, fans suddenly got extremely interested in Michael Jordan. A 10-part documentary on ESPN, \\u201cThe Last Dance,\\u201d set ratings records and dominated the sports conversation.\\\\nThe coronavirus affected everyone, from the small to the mighty. Tom Brady was exercising in a public park in his new hometown, Tampa, Fla., only to be approached by a worker who told him the park was closed.\\\\nIt was all systems go for the N.F.L. draft, live from \\u2026 Roger Goodell\\u2019s basement? The event offered a preview of the 2020 season, a look at the inside of the homes of future stars and the arresting visual of a dog sitting at Bill Belichick\\u2019s desk\\\"\\n 'Instead of talking about football after he joined the New Orleans Saints, Jamaal Williams introduced himself to reporters last year with a dialogue on \\u201cPok\\u00e9mon,\\u201d prompted by the foxlike character Eevee perched on his head.\\\\nIn homage to \\u201cAvatar: The Last Airbender,\\u201d the mixed-martial artist Israel Adesanya has boldly nicknamed himself the Last Stylebender.\\\\nAnd the sprinter Noah Lyles, to celebrate his Olympic gold medal in the 100-meter dash this summer, cupped his hands forward as if generating the \\u201cKamehameha,\\u201d an energy-blast attack from \\u201cDragon Ball Z.\\u201d\\\\nHigh-profile athletes are increasingly broadcasting their fascination with anime, creating a fraternity inside locker rooms as they lovingly dissect favorite animated Japanese shows and films. In the process, they are upending preconceptions about different kinds of fandom and outdated labels that seek to define and divide jocks and geeks.\\\\n\\u201cThere\\u2019s more nerds out here that can ball out and like anime,\\u201d said Williams, 29, who has worn an anime helmet visor and gently corrected a reporter who mispronounced \\u201cPok\\u00e8mon.\\u201d \\u201cYou don\\u2019t have to be the stereotype where all we do is rap or play ball.\\u201d'\\n 'Last month, in a game against the Tampa Bay Buccaneers, the San Francisco 49ers\\u2019 star defensive end, Nick Bosa, celebrated a routine sack with a cheerful and ungainly series of hip-swivels and fist-pumps, not unlike the movements of an automaton gaining sentience.\\\\nThis is what has become known as the Trump dance.\\\\nFor Bosa \\u2014 who had just been fined $11,255, or .033 percent of his $34 million-a-year salary, for sporting a \\u201cMake America Great Again\\u201d hat on the field weeks earlier \\u2014 it was, evidently, an emphatic if tongue-in-cheek salute to the president-elect. The lumbering gestures of politicians rarely trickle down to the football field, but this instance made for a strange kind of harmony: Trump, after all, has perfected in politics exactly the kinds of gloating theatrics we expect from athletes after just about every net-positive play.\\\\nThe Trump dance has become a phenomenon in the world of sports, where the president-elect has long vied for purchase. Sometimes it suggests a resounding endorsement of Trump himself; sometimes it\\u2019s just about the pleasures of stiff gyration. Following Bosa\\u2019s lead, the Las Vegas Raiders tight end Brock Bowers celebrated a recent touchdown with the dance, pumping his fists in the gleefully stodgy manner Trump has at so many rallies. So did Christian Pulisic, a star of the U.S. men\\u2019s national soccer team, who clarified that he was not declaring his support for Trump but merely \\u201cthought it was funny'\\n 'Many Reddit users are boycotting the social media site X, formerly known as Twitter, after Elon Musk twice made a gesture during President Trump\\u2019s inaugural celebration that drew comparisons to the Nazi salute.\\\\n\\\\nMr. Musk, the billionaire owner of the social media platform, was speaking at a celebratory rally after Mr. Trump\\u2019s installment as the 47th president on Monday when he grunted, placed his hand over his heart and lifted his arm with the palm facing down in a hail to the audience.\\\\n\\\\nAlthough Mr. Musk played down the criticism, speculation about the gesture\\u2019s meaning broke out online, including on Reddit, where people gather in thousands of forums known as subreddits to discuss niche interests, including hobbies, sports, celebrity gossip and geopolitics.\\\\n\\\\nBy Tuesday, a proposal had emerged in dozens of Reddit groups across a wide spectrum of interests: Many users wanted to place a ban on linking to X posts as a way of boycotting the platform and Mr. Musk.'\\n 'Aaron Rodgers has been in the spotlight throughout his two-decade N.F.L. career, winning a Super Bowl and four Most Valuable Player awards with the Green Bay Packers while generating headlines about his separation from his parents and his distrust of the coronavirus vaccines.\\\\n\\\\nNetflix captures much of that tension in a three-part docuseries, \\u201cAaron Rodgers: Enigma,\\u201d that starts on Tuesday and follows the quarterback\\u2019s recovery from a torn Achilles\\u2019 tendon minutes into his first game after a high-profile trade to the New York Jets. The project is executive produced by Gotham Chopra, a documentarian who recently profiled Simone Biles and Serena Williams.\\\\n\\\\nRodgers, 41, discusses freewheeling topics during a weekly appearance on an ESPN television show hosted by Pat McAfee, a former N.F.L. player. But he was brusque in a news conference last week when asked about the documentary, looking and sounding annoyed while saying that filmmakers had approached him about following his rehabilitation before the project\\u2019s scope expanded.\\\\n\\\\n\\u201cI\\u2019m glad it\\u2019s done,\\u201d Rodgers said after grimacing and shrugging his shoulders.\\\\n\\\\nHere is a look at three memorable scenes from the documentary.'\\n 'Before the coronavirus started sweeping through the United States, Rudy Gobert of the Utah Jazz decided to mock people\\u2019s fears by touching all of the reporters\\u2019 microphones after a postgame news conference. Two days later, he tested positive for the virus, the first N.B.A. player to do so.\\\\nThe N.B.A. was the first major league to suspend its season. The moment when Mark Cuban, owner of the Dallas Mavericks, learned of the decision on his phone was captured on video, and his astonished reaction was mirrored around the country as sports began to fall like dominoes.\\\\nThe men\\u2019s basketball tournament, the N.C.A.A.\\u2019s primary source of revenue, was canceled, driving home the seriousness of the virus. The cancellation of all spring college sports followed.\\\\nMajor League Baseball, amid spring training, decided the prudent course would be to suspend play and postpone opening day. In a sign that few realized how much the virus would be affecting life for months to come, baseball officials initially delayed the season by only two weeks.\\\\nNick Heath, a suddenly idle British rugby announcer, had a social media moment when his sports-style commentaries on quotidian goings-on in the park and town center went viral. \\u201cIt\\u2019s the final of the two lonely blokes in a park contest.\\u2019\\u2019\\\\nThe biggest shoe dropped. The Tokyo Summer Olympics, a multibillion-dollar event with thousands of moving parts, was postponed by a year.\\\\nWith sports shutting down around the globe, a few places soldiered on']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bm25\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10497 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cd9ff0e35e9441699939d744c2b20a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1167 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6093cf5f914405fb0aa9e05bf34cd13"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from transformers import (\n",
        "    BigBirdTokenizerFast,\n",
        "    BigBirdConfig,\n",
        "    BigBirdModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    classification_report,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "import numpy as np\n",
        "from safetensors.torch import save_file\n",
        "import os\n",
        "import json\n",
        "\n",
        "# =============================================================================\n",
        "# Constants and File Paths\n",
        "# =============================================================================\n",
        "LABEL_COLUMN = 'label'\n",
        "TEXT_COLUMN = 'text'\n",
        "CLUE_COLUMN = 'clue'\n",
        "LABEL_COLUMN_gen = 'generated'\n",
        "TRAIN_FILE = '/content/RAG_results_train.parquet'\n",
        "TEST_FILE = '/content/RAG_results_test1.parquet'\n",
        "MODEL_NAME = 'google/bigbird-roberta-base'\n",
        "OUTPUT_DIR = './output/'\n",
        "\n",
        "# =============================================================================\n",
        "# Data Loading and Preprocessing\n",
        "# =============================================================================\n",
        "def load_data(file_path):\n",
        "    df = pd.read_parquet(file_path)\n",
        "    df = df.copy()\n",
        "    df[LABEL_COLUMN] = df[LABEL_COLUMN_gen].astype(int)\n",
        "    df[TEXT_COLUMN] = df[TEXT_COLUMN].fillna('').astype(str)\n",
        "    df[CLUE_COLUMN] = df[CLUE_COLUMN].fillna('').astype(str)\n",
        "    return df\n",
        "\n",
        "# Load data and create train/validation splits\n",
        "train_df = load_data(TRAIN_FILE)\n",
        "test_df = load_data(TEST_FILE)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "display(train_df.head())\n",
        "\n",
        "# Convert dataframes to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = BigBirdTokenizerFast.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    model_max_length=4096,\n",
        "    padding_side=\"right\",\n",
        "    pad_to_multiple_of=64\n",
        ")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    text_inputs = tokenizer(\n",
        "        examples[TEXT_COLUMN],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=4096,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    clue_inputs = tokenizer(\n",
        "        examples[CLUE_COLUMN],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=768,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": text_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": text_inputs[\"attention_mask\"],\n",
        "        \"clue_input_ids\": clue_inputs[\"input_ids\"],\n",
        "        \"clue_attention_mask\": clue_inputs[\"attention_mask\"],\n",
        "        \"labels\": examples[\"label\"]\n",
        "    }\n",
        "\n",
        "# Apply preprocessing on datasets\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, batch_size=32)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True, batch_size=32)\n",
        "\n",
        "def collate_function(features):\n",
        "    batch = {\n",
        "        \"input_ids\": torch.stack([torch.tensor(f[\"input_ids\"]) for f in features]),\n",
        "        \"attention_mask\": torch.stack([torch.tensor(f[\"attention_mask\"]) for f in features]),\n",
        "        \"clue_input_ids\": torch.stack([torch.tensor(f[\"clue_input_ids\"]) for f in features]),\n",
        "        \"clue_attention_mask\": torch.stack([torch.tensor(f[\"clue_attention_mask\"]) for f in features]),\n",
        "        \"labels\": torch.tensor([f[\"labels\"] for f in features]),\n",
        "    }\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# Model Definition\n",
        "# =============================================================================\n",
        "class DualChannelModel(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, lora_config=None):\n",
        "        super(DualChannelModel, self).__init__()\n",
        "        # Load the base BigBird model\n",
        "        self.bigbird = BigBirdModel.from_pretrained(model_name)\n",
        "\n",
        "        # Apply LoRA if a configuration is provided\n",
        "        if lora_config is not None:\n",
        "            self.bigbird = get_peft_model(self.bigbird, lora_config)  # Only apply LoRA to the BigBird model\n",
        "\n",
        "        # Update the classifier to accept the concatenated features.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(self.bigbird.config.hidden_size * 2, self.bigbird.config.hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.bigbird.config.hidden_size, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, clue_input_ids, clue_attention_mask, labels=None):\n",
        "        # Extract [CLS] token from main input\n",
        "        text_outputs = self.bigbird(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
        "        # Compute mean pooling for the clue input\n",
        "        clue_outputs = self.bigbird(input_ids=clue_input_ids, attention_mask=clue_attention_mask).last_hidden_state.mean(dim=1)\n",
        "        # print(text_outputs.shape)\n",
        "        # print(clue_outputs.shape)\n",
        "\n",
        "        # Concatenate text_outputs and clue_outputs along the feature dimension\n",
        "        fused_features = torch.cat([text_outputs, clue_outputs], dim=1)\n",
        "        # print(fused_features.shape)\n",
        "\n",
        "        logits = self.classifier(fused_features)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "    def save(self, output_dir):\n",
        "        \"\"\"Custom method to save the model and LoRA config\"\"\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Save the model's state_dict\n",
        "        torch.save(self.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
        "\n",
        "        # Save the LoRA config if available\n",
        "        if hasattr(self, 'bigbird') and hasattr(self.bigbird, 'config') and self.bigbird.config:\n",
        "            lora_config_path = os.path.join(output_dir, \"adapter_config.json\")\n",
        "            config = self.bigbird.config.to_dict()  # Assuming LoRA config is part of the BigBird model config\n",
        "            with open(lora_config_path, \"w\") as f:\n",
        "                json.dump(config, f)\n",
        "\n",
        "        print(f\"✅ Model and LoRA adapter saved to {output_dir}\")\n",
        "\n",
        "# Utility function to compute and print the model size in MB\n",
        "def print_model_size(model):\n",
        "    param_size = sum(param.nelement() * param.element_size() for param in model.parameters())\n",
        "    buffer_size = sum(buffer.nelement() * buffer.element_size() for buffer in model.buffers())\n",
        "    size_mb = (param_size + buffer_size) / 1024 ** 2\n",
        "    print(f\"Model size: {size_mb:.3f} MB\")\n",
        "\n",
        "# Example model name and configuration\n",
        "model_name = \"google/bigbird-roberta-base\"  # Replace with your model name if needed\n",
        "num_labels = 2\n",
        "model = DualChannelModel(model_name, num_labels)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "batch_size = 2\n",
        "seq_length = 16\n",
        "\n",
        "# Create dummy inputs\n",
        "input_ids = torch.randint(0, 1000, (batch_size, seq_length))\n",
        "attention_mask = torch.ones((batch_size, seq_length), dtype=torch.long)\n",
        "clue_input_ids = torch.randint(0, 1000, (batch_size, seq_length))\n",
        "clue_attention_mask = torch.ones((batch_size, seq_length), dtype=torch.long)\n",
        "labels = torch.randint(0, num_labels, (batch_size,))\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask, clue_input_ids, clue_attention_mask, labels)\n",
        "print(\"Test output:\", outputs)\n",
        "\n",
        "# Debug: print out the model size\n",
        "print_model_size(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOPQVdb4HmgU",
        "outputId": "a595f6fe-f0aa-4dd7-c98c-f728348a7683"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 16 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test output: {'loss': tensor(0.6913), 'logits': tensor([[-0.0962, -0.1493],\n",
            "        [-0.0738, -0.1362]])}\n",
            "Model size: 490.826 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Training Setup\n",
        "# =============================================================================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,      # Further reduced batch size\n",
        "    per_device_eval_batch_size=1,       # Further reduced batch size\n",
        "    gradient_accumulation_steps=4,       # Effective batch size of 4\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=50,\n",
        "    warmup_ratio=0.1,\n",
        "    report_to=\"none\",\n",
        "    fp16=True,                         # Enable mixed precision training\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        \"query\", \"key\", \"value\",\n",
        "        \"output.dense\",\n",
        "        \"classifier.out_proj\"\n",
        "    ],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\",\n",
        ")\n",
        "\n",
        "model = DualChannelModel(MODEL_NAME, num_labels=2, lora_config=lora_config)\n",
        "\n",
        "# Enable gradient checkpointing to reduce memory usage\n",
        "model.bigbird.config.gradient_checkpointing = True\n",
        "# 计算可训练参数的总数\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"Trainable Parameters: {trainable_params} / {total_params} ({trainable_params / total_params:.2%})\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def _save(self, output_dir: str, state_dict=None):\n",
        "        \"\"\"自定义保存方法，确保同时保存模型权重和 LoRA 适配器\"\"\"\n",
        "\n",
        "        print(f\"\\n🔍 Saving model and adapter to {output_dir} ...\")\n",
        "\n",
        "        # 1. 确保 `state_dict` 处于 contiguous 状态\n",
        "        if state_dict is None:\n",
        "            state_dict = {\n",
        "                key: value.contiguous() if not value.is_contiguous() else value\n",
        "                for key, value in self.model.state_dict().items()\n",
        "            }\n",
        "\n",
        "        # 2. 调用 Trainer 的原始 `_save()` 方法，保存基础模型权重\n",
        "        super()._save(output_dir, state_dict=state_dict)\n",
        "\n",
        "        # 3. 保存 LoRA 适配器\n",
        "        adapter_output_dir = os.path.join(output_dir, \"checkpoint-lora\")\n",
        "        self.model.save(adapter_output_dir)\n",
        "\n",
        "        # 4. 保存 `safetensors` 权重\n",
        "        safetensors_path = os.path.join(adapter_output_dir, \"model.safetensors\")\n",
        "        save_file(state_dict, safetensors_path)\n",
        "\n",
        "        print(f\"✅ Model and adapter saved successfully to {adapter_output_dir}\")\n",
        "\n",
        "        # 5. 确保 `adapter_config.json` 存在\n",
        "        adapter_config_path = os.path.join(adapter_output_dir, \"adapter_config.json\")\n",
        "        if not os.path.exists(adapter_config_path):\n",
        "            raise FileNotFoundError(f\"❌ {adapter_config_path} 没有正确保存，请检查训练过程！\")\n",
        "\n",
        "        print(f\"✅ Adapter config verified at {adapter_config_path}.\")\n",
        "\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=collate_function,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# Training\n",
        "# =============================================================================\n",
        "trainer.train()\n",
        "\n",
        "# =============================================================================\n",
        "# Prediction and Evaluation\n",
        "# =============================================================================\n",
        "def predict(model, texts, clues, batch_size=8):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        batch_clues = clues[i:i+batch_size]\n",
        "\n",
        "        text_inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=4096,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        clue_inputs = tokenizer(\n",
        "            batch_clues,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=4096,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                input_ids=text_inputs[\"input_ids\"],\n",
        "                attention_mask=text_inputs[\"attention_mask\"],\n",
        "                clue_input_ids=clue_inputs[\"input_ids\"],\n",
        "                clue_attention_mask=clue_inputs[\"attention_mask\"]\n",
        "            )\n",
        "        probs = torch.softmax(outputs[\"logits\"], dim=-1)[:, 1].cpu().numpy()\n",
        "        predictions.extend(probs)\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Prepare test set lists\n",
        "texts = test_df[TEXT_COLUMN].tolist()\n",
        "clues = test_df[CLUE_COLUMN].tolist()\n",
        "labels = test_df[\"label\"].tolist()\n",
        "\n",
        "predictions = predict(model, texts, clues, batch_size=4)\n",
        "\n",
        "def evaluate(y_true, y_pred_probs, threshold=0.5):\n",
        "    y_pred = (y_pred_probs >= threshold).astype(int)\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"真实\", \"虚假\"], zero_division=0))\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "results = evaluate(labels, predictions)\n",
        "for k, v in results.items():\n",
        "    print(f\"{k.upper():<10}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "MJ1uUzWaGEjH",
        "outputId": "43a92e88-f022-4300-803b-804cad31506f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Parameters: 2140418 / 129609218 (1.65%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7872' max='7872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7872/7872 4:38:05, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.048300</td>\n",
              "      <td>0.095869</td>\n",
              "      <td>0.978578</td>\n",
              "      <td>0.962025</td>\n",
              "      <td>0.992537</td>\n",
              "      <td>0.977043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>0.036590</td>\n",
              "      <td>0.993145</td>\n",
              "      <td>0.988889</td>\n",
              "      <td>0.996269</td>\n",
              "      <td>0.992565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Saving model and adapter to ./output/checkpoint-2625 ...\n",
            "✅ Model and LoRA adapter saved to ./output/checkpoint-2625/checkpoint-lora\n",
            "✅ Model and adapter saved successfully to ./output/checkpoint-2625/checkpoint-lora\n",
            "✅ Adapter config verified at ./output/checkpoint-2625/checkpoint-lora/adapter_config.json.\n",
            "\n",
            "🔍 Saving model and adapter to ./output/checkpoint-5250 ...\n",
            "✅ Model and LoRA adapter saved to ./output/checkpoint-5250/checkpoint-lora\n",
            "✅ Model and adapter saved successfully to ./output/checkpoint-5250/checkpoint-lora\n",
            "✅ Adapter config verified at ./output/checkpoint-5250/checkpoint-lora/adapter_config.json.\n",
            "\n",
            "🔍 Saving model and adapter to ./output/checkpoint-7872 ...\n",
            "✅ Model and LoRA adapter saved to ./output/checkpoint-7872/checkpoint-lora\n",
            "✅ Model and adapter saved successfully to ./output/checkpoint-7872/checkpoint-lora\n",
            "✅ Adapter config verified at ./output/checkpoint-7872/checkpoint-lora/adapter_config.json.\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          真实       1.00      0.97      0.98       860\n",
            "          虚假       0.98      1.00      0.99       978\n",
            "\n",
            "    accuracy                           0.99      1838\n",
            "   macro avg       0.99      0.98      0.99      1838\n",
            "weighted avg       0.99      0.99      0.99      1838\n",
            "\n",
            "ACCURACY  : 0.9853\n",
            "PRECISION : 0.9760\n",
            "RECALL    : 0.9969\n",
            "F1        : 0.9863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "IWTd-DqMPoIl",
        "outputId": "f53bc17c-850c-4803-b777-07d93ff9a982"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Agony for Kane Williamson, ecstasy for Matthew Potts. Granted, it may not trip off the tongue like Ian Smith’s famous commentary at Lord’s five years ago, but both emotions were very much on show after the moment that changed day one in Hamilton. Williamson had looked indelible during the opening exchanges of this third Test, cruising to 44 and driving New Zealand to an apparent position of strength at 185 for three after tea. But when he was bowled by Potts, having deflected the ball on to his stumps playing late to one that bounced, England’s fightback was sparked. “I didn’t have a great view of it,” said Potts as New Zealand closed on 315 for nine at stumps, the seamer having claimed three for 75 on his return to England’s XI. “I was a bit confused but then I saw a bail drop down by his feet and it was pure elation after that.” Asked about his personal success against Williamson, a hold that has returned four dismissals from five encounters, Potts said: “It was a massive wicket at that point in the innings. It’s less about personal milestones and achievements of getting good players out. At that key point in time, Kane could have taken the game away from us. “To get a massive scalp like that for the team, a player like Kane who can play the long game and score quite quickly as well, I’m pretty proud of that.” Potts has spent much of the year in the wings, having impressed on a Lions tour of India at the back end of last winter, only then to wait until the second summer series, against Sri Lanka, for his chance. Even then, after two solid performances, the 26‑year‑old was left out to give the untried Josh Hull a debut at the Oval, with Potts’s one-off appearance in Pakistan in October his first cap away from home. Few players have bought further into the team-first approach of Ben Stokes, however, with Potts in awe at his captain and Durham teammate sending down 23 overs in three spells here. That time spent on the sidelines was not exactly wasted either, with Potts a relentless workhorse for England’s batters in the nets while honing his technique under the watchful eye of Jimmy Anderson. Potts said: “I enjoy every time that I put this England shirt on and I just hope I do it justice. Competition is really high and that’s great for the team. These things happen, you travel around a little bit and don’t play, but then you get an opportunity. “I’ve learned a little bit from [Anderson], doing a little bit of run-up work, tinkering with a few deliveries and building up a bit of confidence with the new ball. So yes, I’ve added a few strings to my bow.”'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Save Prediction Results to File\n",
        "# =============================================================================\n",
        "prediction_df = pd.DataFrame({\n",
        "    \"text\": texts,\n",
        "    \"clue\": clues,\n",
        "    \"true_label\": labels,\n",
        "    \"predicted_probability\": predictions\n",
        "})\n",
        "prediction_df.to_csv(\"predictions_test1.csv\", index=False)\n",
        "print(\"Prediction results have been stored in 'predictions_test1.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPYP7tjm7ArU",
        "outputId": "064cbbf9-1478-4fbe-8ab4-34d31e01d457"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results have been stored in 'predictions_test1.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "# 1. 初始化模型\n",
        "model = DualChannelModel(MODEL_NAME, num_labels=2, lora_config=lora_config)\n",
        "model.bigbird.config.gradient_checkpointing = True  # 可选\n",
        "\n",
        "# 2. 读取权重\n",
        "checkpoint_path = \"output/checkpoint-7872\"\n",
        "checkpoint_file = os.path.join(checkpoint_path, \"model.safetensors\")\n",
        "\n",
        "if not os.path.exists(checkpoint_file):\n",
        "    raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_file}\")\n",
        "\n",
        "state_dict = load_file(checkpoint_file)\n",
        "\n",
        "# 3. 设备匹配\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "state_dict = {k: v.to(device) for k, v in state_dict.items()}  # 转换权重设备\n",
        "\n",
        "# 4. 加载权重（允许部分不匹配）\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 5. 加载测试数据\n",
        "TEST_FILE2 = '/content/RAG_results_test2.parquet'\n",
        "test_df2 = load_data(TEST_FILE2)\n",
        "\n",
        "texts2 = test_df2[TEXT_COLUMN].tolist()\n",
        "clues2 = test_df2[CLUE_COLUMN].tolist()\n",
        "labels2 = test_df2[\"generated\"].tolist()\n",
        "\n",
        "# 6. 预测\n",
        "predictions2 = predict(model, texts2, clues2, batch_size=4)\n",
        "\n",
        "# 7. 评估\n",
        "print(\"\\n=== Inference on Test2 Data ===\")\n",
        "results2 = evaluate(labels2, predictions2)\n",
        "for k, v in results2.items():\n",
        "    print(f\"TEST2 {k.upper():<10}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9viDt5Pilc8",
        "outputId": "10fe85e9-df9a-4ef0-8fde-b0e907c4c57d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Inference on Test2 Data ===\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          真实       1.00      0.96      0.98       750\n",
            "          虚假       0.97      1.00      0.98       868\n",
            "\n",
            "    accuracy                           0.98      1618\n",
            "   macro avg       0.98      0.98      0.98      1618\n",
            "weighted avg       0.98      0.98      0.98      1618\n",
            "\n",
            "TEST2 ACCURACY  : 0.9802\n",
            "TEST2 PRECISION : 0.9665\n",
            "TEST2 RECALL    : 0.9977\n",
            "TEST2 F1        : 0.9819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Save Prediction Results to File\n",
        "# =============================================================================\n",
        "prediction_df = pd.DataFrame({\n",
        "    \"text\": texts2,\n",
        "    \"clue\": clues2,\n",
        "    \"true_label\": labels2,\n",
        "    \"predicted_probability\": predictions2\n",
        "})\n",
        "prediction_df.to_csv(\"predictions_test2.csv\", index=False)\n",
        "print(\"Prediction results have been stored in 'predictions_test2.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrC8A09K_SfV",
        "outputId": "02b3c3fe-4ef4-4886-c3d6-4bf90369927b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results have been stored in 'predictions_test2.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r checkpoint.zip /content/output/checkpoint-7872"
      ],
      "metadata": {
        "id": "63HY-TOCjKf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1c970d-7668-42d6-a893-d193663e361a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/checkpoint-7872/ (stored 0%)\n",
            "  adding: content/output/checkpoint-7872/checkpoint-lora/ (stored 0%)\n",
            "  adding: content/output/checkpoint-7872/checkpoint-lora/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/output/checkpoint-7872/checkpoint-lora/model.safetensors (deflated 7%)\n",
            "  adding: content/output/checkpoint-7872/checkpoint-lora/adapter_config.json (deflated 58%)\n",
            "  adding: content/output/checkpoint-7872/trainer_state.json (deflated 78%)\n",
            "  adding: content/output/checkpoint-7872/scaler.pt (deflated 60%)\n",
            "  adding: content/output/checkpoint-7872/scheduler.pt (deflated 55%)\n",
            "  adding: content/output/checkpoint-7872/model.safetensors (deflated 7%)\n",
            "  adding: content/output/checkpoint-7872/training_args.bin (deflated 51%)\n",
            "  adding: content/output/checkpoint-7872/optimizer.pt (deflated 7%)\n",
            "  adding: content/output/checkpoint-7872/rng_state.pth (deflated 25%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"checkpoint.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pW0zENmWeuFI",
        "outputId": "1da1a06f-3888-43f0-832e-e2c3818456f6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a66655a-60ae-4de5-a8cb-30dc512404d5\", \"checkpoint.zip\", 1458677314)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"predictions_test1.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tREI7lILe3-l",
        "outputId": "811aed73-695f-4022-a04f-bc41f43ac2d0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_87f556a2-c58e-4ea4-9dc0-d5540843fb3b\", \"predictions_test1.csv\", 30518556)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"predictions_test2.csv\")"
      ],
      "metadata": {
        "id": "g8Nh8_cofpHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e84a8503-6868-4d4d-8604-80e850f774ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_51a3424b-2e35-4ff3-875a-5645870211af\", \"predictions_test2.csv\", 26900275)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SpKSZfXNfhaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}