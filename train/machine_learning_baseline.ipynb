{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Baseline (With Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:40:19.466849Z",
     "iopub.status.busy": "2025-02-24T19:40:19.466282Z",
     "iopub.status.idle": "2025-02-24T19:40:21.257291Z",
     "shell.execute_reply": "2025-02-24T19:40:21.256285Z",
     "shell.execute_reply.started": "2025-02-24T19:40:19.466813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(r'..\\data\\Dataset\\train_final.csv')\n",
    "test = pd.read_csv(r'..\\data\\Dataset\\test1_final.csv')\n",
    "test2 = pd.read_csv(r'..\\data\\Dataset\\test2_final.csv')\n",
    "\n",
    "print(\"shape: \", train.shape)\n",
    "display(train.head())\n",
    "display(train.tail())\n",
    "\n",
    "print(\"shape: \", test.shape)\n",
    "display(test.head())\n",
    "display(test.tail())\n",
    "\n",
    "print(\"shape: \", test2.shape)\n",
    "display(test2.head())\n",
    "display(test2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:45:57.182757Z",
     "iopub.status.busy": "2025-02-24T19:45:57.182358Z",
     "iopub.status.idle": "2025-02-24T19:48:02.109366Z",
     "shell.execute_reply": "2025-02-24T19:48:02.108197Z",
     "shell.execute_reply.started": "2025-02-24T19:45:57.182728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tokenizers import normalizers, pre_tokenizers, trainers, Tokenizer, models\n",
    "from datasets import Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import scipy.sparse as sp\n",
    "\n",
    "target_col = 'text'\n",
    "\n",
    "train[target_col] = train[target_col].astype(str).str.strip()\n",
    "test[target_col] = test[target_col].astype(str).str.strip()\n",
    "\n",
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 30522\n",
    "\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "raw_tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFC()] + ([normalizers.Lowercase()] if LOWERCASE else [])\n",
    ")\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n",
    "\n",
    "hq_pers = pd.read_csv('/kaggle/input/persuade-2-0/persuade_2.0_human_scores_demo_id_github.csv')\n",
    "hq_pers = hq_pers[hq_pers['holistic_essay_score'] > 4]\n",
    "hq_pers.rename(columns={'full_text': target_col}, inplace=True)\n",
    "\n",
    "tokenizer_df = pd.concat([test, hq_pers])\n",
    "dataset = Dataset.from_pandas(tokenizer_df[[target_col]])\n",
    "\n",
    "def train_corp_iter(): \n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][target_col]\n",
    "\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "tokenizer.save_pretrained('persuade_tokenizer')\n",
    "\n",
    "tokenized_texts_test = [tokenizer.tokenize(t) for t in test[target_col].tolist()]\n",
    "tokenized_texts_train = [tokenizer.tokenize(t) for t in train[target_col].tolist()]\n",
    "\n",
    "def dummy(text):\n",
    "    return text\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(3, 5),\n",
    "    lowercase=False,\n",
    "    sublinear_tf=True,\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    "    token_pattern=None,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "vectorizer.fit(tokenized_texts_test)\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(3, 5),\n",
    "    lowercase=False,\n",
    "    sublinear_tf=True,\n",
    "    vocabulary=vocab,\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    "    token_pattern=None,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "tf_train = vectorizer.fit_transform(tokenized_texts_train)\n",
    "tf_test = vectorizer.transform(tokenized_texts_test)\n",
    "\n",
    "print(tf_train.shape)\n",
    "print(tf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:48:02.111470Z",
     "iopub.status.busy": "2025-02-24T19:48:02.111039Z",
     "iopub.status.idle": "2025-02-24T19:48:02.350422Z",
     "shell.execute_reply": "2025-02-24T19:48:02.348604Z",
     "shell.execute_reply.started": "2025-02-24T19:48:02.111438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_parquet(r\"..\\data\\Retriever Dataset\\RAG_results_train_features.parquet\")\n",
    "test_features = pd.read_parquet(r\"..\\data\\Retriever Dataset\\RAG_results_test1_features.parquet\")\n",
    "\n",
    "train_features_sparse = sp.csr_matrix(train_features.values)\n",
    "test_features_sparse = sp.csr_matrix(test_features.values)\n",
    "\n",
    "tf_train = sp.hstack([tf_train, train_features_sparse])\n",
    "tf_test = sp.hstack([tf_test, test_features_sparse])\n",
    "\n",
    "print(tf_train.shape)\n",
    "print(tf_test.shape)\n",
    "\n",
    "y_train = train['generated'].values\n",
    "\n",
    "estimators = [\n",
    "    ('mnb', MultinomialNB(alpha=0.02)),\n",
    "    ('sgd', SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\")),\n",
    "    ('lgb', LGBMClassifier(learning_rate=0.05))\n",
    "]\n",
    "weights = [0.05, 0.225, 0.5]\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    weights=weights, voting='soft', n_jobs=-1\n",
    ")\n",
    "ensemble.fit(tf_train, y_train)\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:49:26.160124Z",
     "iopub.status.busy": "2025-02-24T19:49:26.159819Z",
     "iopub.status.idle": "2025-02-24T19:49:26.183602Z",
     "shell.execute_reply": "2025-02-24T19:49:26.182517Z",
     "shell.execute_reply.started": "2025-02-24T19:49:26.160098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:49:26.186204Z",
     "iopub.status.busy": "2025-02-24T19:49:26.185738Z",
     "iopub.status.idle": "2025-02-24T19:50:05.242666Z",
     "shell.execute_reply": "2025-02-24T19:50:05.241530Z",
     "shell.execute_reply.started": "2025-02-24T19:49:26.186136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf_vectors = tf_test.toarray()\n",
    "y_true = test['generated'].values\n",
    "\n",
    "final_preds_proba = ensemble.predict_proba(tf_vectors)[:, 1]\n",
    "\n",
    "y_pred = (final_preds_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y_true': y_true, \n",
    "    'y_pred': y_pred,\n",
    "    'predicted_proba': final_preds_proba\n",
    "})\n",
    "\n",
    "df.to_csv('ml_prediction_test1.csv', index=False)\n",
    "\n",
    "print(\"ml_prediction_test1.csv 已成功保存！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:50:05.243993Z",
     "iopub.status.busy": "2025-02-24T19:50:05.243707Z",
     "iopub.status.idle": "2025-02-24T19:50:05.250196Z",
     "shell.execute_reply": "2025-02-24T19:50:05.248794Z",
     "shell.execute_reply.started": "2025-02-24T19:50:05.243969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = (final_preds_proba >= 0.5).astype(int)\n",
    "\n",
    "accuracy = (y_pred == y_true).mean()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:50:05.251873Z",
     "iopub.status.busy": "2025-02-24T19:50:05.251531Z",
     "iopub.status.idle": "2025-02-24T19:50:05.276366Z",
     "shell.execute_reply": "2025-02-24T19:50:05.275124Z",
     "shell.execute_reply.started": "2025-02-24T19:50:05.251843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1737045,
     "sourceId": 2838907,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5080176,
     "sourceId": 8510508,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6624259,
     "sourceId": 10691032,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6709680,
     "sourceId": 10834619,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6631713,
     "sourceId": 10843906,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 28847,
     "modelInstanceId": 18893,
     "sourceId": 22784,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 239061,
     "modelInstanceId": 217345,
     "sourceId": 254204,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
