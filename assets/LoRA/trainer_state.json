{
  "best_metric": 0.17484153807163239,
  "best_model_checkpoint": "./longformer_lora_results/checkpoint-1968",
  "epoch": 2.9965714285714284,
  "eval_steps": 500,
  "global_step": 1968,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015238095238095238,
      "grad_norm": 1.3065754175186157,
      "learning_rate": 1.0152284263959392e-06,
      "loss": 0.7085,
      "step": 10
    },
    {
      "epoch": 0.030476190476190476,
      "grad_norm": 1.2110261917114258,
      "learning_rate": 2.0304568527918785e-06,
      "loss": 0.6868,
      "step": 20
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 0.9534965753555298,
      "learning_rate": 3.0456852791878177e-06,
      "loss": 0.6849,
      "step": 30
    },
    {
      "epoch": 0.06095238095238095,
      "grad_norm": 3.5080549716949463,
      "learning_rate": 4.060913705583757e-06,
      "loss": 0.6752,
      "step": 40
    },
    {
      "epoch": 0.0761904761904762,
      "grad_norm": 2.9132585525512695,
      "learning_rate": 5.076142131979695e-06,
      "loss": 0.7056,
      "step": 50
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.9197503924369812,
      "learning_rate": 6.091370558375635e-06,
      "loss": 0.698,
      "step": 60
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.342517375946045,
      "learning_rate": 7.106598984771575e-06,
      "loss": 0.6862,
      "step": 70
    },
    {
      "epoch": 0.1219047619047619,
      "grad_norm": 0.9478759169578552,
      "learning_rate": 8.121827411167514e-06,
      "loss": 0.6994,
      "step": 80
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 2.2879436016082764,
      "learning_rate": 9.137055837563452e-06,
      "loss": 0.685,
      "step": 90
    },
    {
      "epoch": 0.1523809523809524,
      "grad_norm": 0.9850623607635498,
      "learning_rate": 1.015228426395939e-05,
      "loss": 0.6895,
      "step": 100
    },
    {
      "epoch": 0.1676190476190476,
      "grad_norm": 2.355548620223999,
      "learning_rate": 1.116751269035533e-05,
      "loss": 0.6716,
      "step": 110
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 3.735856056213379,
      "learning_rate": 1.218274111675127e-05,
      "loss": 0.6639,
      "step": 120
    },
    {
      "epoch": 0.1980952380952381,
      "grad_norm": 4.455934047698975,
      "learning_rate": 1.3197969543147209e-05,
      "loss": 0.6851,
      "step": 130
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 1.1505119800567627,
      "learning_rate": 1.421319796954315e-05,
      "loss": 0.6762,
      "step": 140
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 1.093177318572998,
      "learning_rate": 1.5228426395939086e-05,
      "loss": 0.6549,
      "step": 150
    },
    {
      "epoch": 0.2438095238095238,
      "grad_norm": 1.7968590259552002,
      "learning_rate": 1.6243654822335028e-05,
      "loss": 0.6597,
      "step": 160
    },
    {
      "epoch": 0.259047619047619,
      "grad_norm": 1.096497893333435,
      "learning_rate": 1.7258883248730966e-05,
      "loss": 0.6432,
      "step": 170
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 2.685110092163086,
      "learning_rate": 1.8274111675126904e-05,
      "loss": 0.6351,
      "step": 180
    },
    {
      "epoch": 0.2895238095238095,
      "grad_norm": 1.436879277229309,
      "learning_rate": 1.9289340101522843e-05,
      "loss": 0.6435,
      "step": 190
    },
    {
      "epoch": 0.3047619047619048,
      "grad_norm": 0.938174843788147,
      "learning_rate": 1.9966120835686053e-05,
      "loss": 0.6253,
      "step": 200
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.564635992050171,
      "learning_rate": 1.98531902879729e-05,
      "loss": 0.6279,
      "step": 210
    },
    {
      "epoch": 0.3352380952380952,
      "grad_norm": 1.9718568325042725,
      "learning_rate": 1.974025974025974e-05,
      "loss": 0.6189,
      "step": 220
    },
    {
      "epoch": 0.3504761904761905,
      "grad_norm": 1.3974597454071045,
      "learning_rate": 1.9627329192546585e-05,
      "loss": 0.6054,
      "step": 230
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 1.1779853105545044,
      "learning_rate": 1.951439864483343e-05,
      "loss": 0.6025,
      "step": 240
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 0.9727907776832581,
      "learning_rate": 1.9401468097120272e-05,
      "loss": 0.592,
      "step": 250
    },
    {
      "epoch": 0.3961904761904762,
      "grad_norm": 2.2183027267456055,
      "learning_rate": 1.9288537549407116e-05,
      "loss": 0.579,
      "step": 260
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 1.623633861541748,
      "learning_rate": 1.917560700169396e-05,
      "loss": 0.5897,
      "step": 270
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 1.8008290529251099,
      "learning_rate": 1.9062676453980804e-05,
      "loss": 0.5736,
      "step": 280
    },
    {
      "epoch": 0.4419047619047619,
      "grad_norm": 1.3021607398986816,
      "learning_rate": 1.8949745906267647e-05,
      "loss": 0.5641,
      "step": 290
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.9476460218429565,
      "learning_rate": 1.883681535855449e-05,
      "loss": 0.5735,
      "step": 300
    },
    {
      "epoch": 0.4723809523809524,
      "grad_norm": 1.6516071557998657,
      "learning_rate": 1.8723884810841335e-05,
      "loss": 0.5351,
      "step": 310
    },
    {
      "epoch": 0.4876190476190476,
      "grad_norm": 3.343904972076416,
      "learning_rate": 1.861095426312818e-05,
      "loss": 0.54,
      "step": 320
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 1.7586416006088257,
      "learning_rate": 1.849802371541502e-05,
      "loss": 0.5489,
      "step": 330
    },
    {
      "epoch": 0.518095238095238,
      "grad_norm": 3.447082042694092,
      "learning_rate": 1.8385093167701863e-05,
      "loss": 0.5221,
      "step": 340
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.2693891525268555,
      "learning_rate": 1.827216261998871e-05,
      "loss": 0.5112,
      "step": 350
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 1.3734533786773682,
      "learning_rate": 1.815923207227555e-05,
      "loss": 0.4984,
      "step": 360
    },
    {
      "epoch": 0.5638095238095238,
      "grad_norm": 5.528997898101807,
      "learning_rate": 1.8046301524562395e-05,
      "loss": 0.499,
      "step": 370
    },
    {
      "epoch": 0.579047619047619,
      "grad_norm": 3.9386327266693115,
      "learning_rate": 1.793337097684924e-05,
      "loss": 0.502,
      "step": 380
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 0.9926629066467285,
      "learning_rate": 1.7820440429136082e-05,
      "loss": 0.4971,
      "step": 390
    },
    {
      "epoch": 0.6095238095238096,
      "grad_norm": 1.6423946619033813,
      "learning_rate": 1.7707509881422926e-05,
      "loss": 0.4672,
      "step": 400
    },
    {
      "epoch": 0.6247619047619047,
      "grad_norm": 3.293262004852295,
      "learning_rate": 1.759457933370977e-05,
      "loss": 0.4912,
      "step": 410
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8632067441940308,
      "learning_rate": 1.7481648785996614e-05,
      "loss": 0.4621,
      "step": 420
    },
    {
      "epoch": 0.6552380952380953,
      "grad_norm": 3.533491373062134,
      "learning_rate": 1.7368718238283458e-05,
      "loss": 0.4465,
      "step": 430
    },
    {
      "epoch": 0.6704761904761904,
      "grad_norm": 1.1897451877593994,
      "learning_rate": 1.72557876905703e-05,
      "loss": 0.4515,
      "step": 440
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 1.5636152029037476,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.4381,
      "step": 450
    },
    {
      "epoch": 0.700952380952381,
      "grad_norm": 2.6453311443328857,
      "learning_rate": 1.702992659514399e-05,
      "loss": 0.4657,
      "step": 460
    },
    {
      "epoch": 0.7161904761904762,
      "grad_norm": 1.1279516220092773,
      "learning_rate": 1.6916996047430833e-05,
      "loss": 0.4166,
      "step": 470
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 1.2712293863296509,
      "learning_rate": 1.6804065499717673e-05,
      "loss": 0.4361,
      "step": 480
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.9291493892669678,
      "learning_rate": 1.669113495200452e-05,
      "loss": 0.396,
      "step": 490
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 2.837818145751953,
      "learning_rate": 1.657820440429136e-05,
      "loss": 0.4085,
      "step": 500
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 1.4484163522720337,
      "learning_rate": 1.6465273856578205e-05,
      "loss": 0.4098,
      "step": 510
    },
    {
      "epoch": 0.7923809523809524,
      "grad_norm": 1.2130756378173828,
      "learning_rate": 1.635234330886505e-05,
      "loss": 0.3858,
      "step": 520
    },
    {
      "epoch": 0.8076190476190476,
      "grad_norm": 2.246443748474121,
      "learning_rate": 1.6239412761151892e-05,
      "loss": 0.3918,
      "step": 530
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 3.224473237991333,
      "learning_rate": 1.6126482213438736e-05,
      "loss": 0.3997,
      "step": 540
    },
    {
      "epoch": 0.8380952380952381,
      "grad_norm": 1.8516680002212524,
      "learning_rate": 1.601355166572558e-05,
      "loss": 0.3919,
      "step": 550
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 2.477715492248535,
      "learning_rate": 1.5900621118012424e-05,
      "loss": 0.3847,
      "step": 560
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 2.137087345123291,
      "learning_rate": 1.5787690570299268e-05,
      "loss": 0.3519,
      "step": 570
    },
    {
      "epoch": 0.8838095238095238,
      "grad_norm": 1.7264597415924072,
      "learning_rate": 1.567476002258611e-05,
      "loss": 0.3436,
      "step": 580
    },
    {
      "epoch": 0.8990476190476191,
      "grad_norm": 1.3767147064208984,
      "learning_rate": 1.5561829474872955e-05,
      "loss": 0.3265,
      "step": 590
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 1.510732650756836,
      "learning_rate": 1.54488989271598e-05,
      "loss": 0.3241,
      "step": 600
    },
    {
      "epoch": 0.9295238095238095,
      "grad_norm": 1.6090346574783325,
      "learning_rate": 1.5335968379446643e-05,
      "loss": 0.3406,
      "step": 610
    },
    {
      "epoch": 0.9447619047619048,
      "grad_norm": 3.0021004676818848,
      "learning_rate": 1.5223037831733485e-05,
      "loss": 0.3203,
      "step": 620
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.8895320892333984,
      "learning_rate": 1.5110107284020327e-05,
      "loss": 0.306,
      "step": 630
    },
    {
      "epoch": 0.9752380952380952,
      "grad_norm": 2.524026393890381,
      "learning_rate": 1.4997176736307173e-05,
      "loss": 0.3336,
      "step": 640
    },
    {
      "epoch": 0.9904761904761905,
      "grad_norm": 1.542156457901001,
      "learning_rate": 1.4884246188594017e-05,
      "loss": 0.2816,
      "step": 650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9434447300771208,
      "eval_f1": 0.9406474820143885,
      "eval_loss": 0.29448968172073364,
      "eval_precision": 0.9079861111111112,
      "eval_recall": 0.9757462686567164,
      "eval_runtime": 55.9788,
      "eval_samples_per_second": 20.847,
      "eval_steps_per_second": 5.216,
      "step": 657
    },
    {
      "epoch": 1.0045714285714287,
      "grad_norm": 1.0676379203796387,
      "learning_rate": 1.4771315640880859e-05,
      "loss": 0.2433,
      "step": 660
    },
    {
      "epoch": 1.0198095238095237,
      "grad_norm": 2.5926713943481445,
      "learning_rate": 1.4658385093167704e-05,
      "loss": 0.3138,
      "step": 670
    },
    {
      "epoch": 1.035047619047619,
      "grad_norm": 1.3980317115783691,
      "learning_rate": 1.4545454545454546e-05,
      "loss": 0.3065,
      "step": 680
    },
    {
      "epoch": 1.0502857142857143,
      "grad_norm": 0.9989803433418274,
      "learning_rate": 1.443252399774139e-05,
      "loss": 0.2887,
      "step": 690
    },
    {
      "epoch": 1.0655238095238095,
      "grad_norm": 1.460796594619751,
      "learning_rate": 1.4319593450028232e-05,
      "loss": 0.2774,
      "step": 700
    },
    {
      "epoch": 1.0807619047619048,
      "grad_norm": 3.134957790374756,
      "learning_rate": 1.4206662902315078e-05,
      "loss": 0.292,
      "step": 710
    },
    {
      "epoch": 1.096,
      "grad_norm": 1.4471933841705322,
      "learning_rate": 1.4093732354601922e-05,
      "loss": 0.2688,
      "step": 720
    },
    {
      "epoch": 1.1112380952380951,
      "grad_norm": 1.272020697593689,
      "learning_rate": 1.3980801806888764e-05,
      "loss": 0.2651,
      "step": 730
    },
    {
      "epoch": 1.1264761904761904,
      "grad_norm": 1.830993890762329,
      "learning_rate": 1.3867871259175608e-05,
      "loss": 0.2971,
      "step": 740
    },
    {
      "epoch": 1.1417142857142857,
      "grad_norm": 1.5082728862762451,
      "learning_rate": 1.3754940711462453e-05,
      "loss": 0.2457,
      "step": 750
    },
    {
      "epoch": 1.156952380952381,
      "grad_norm": 1.73593270778656,
      "learning_rate": 1.3642010163749295e-05,
      "loss": 0.3197,
      "step": 760
    },
    {
      "epoch": 1.1721904761904762,
      "grad_norm": 1.0731360912322998,
      "learning_rate": 1.3529079616036137e-05,
      "loss": 0.2556,
      "step": 770
    },
    {
      "epoch": 1.1874285714285715,
      "grad_norm": 1.0745553970336914,
      "learning_rate": 1.3416149068322983e-05,
      "loss": 0.2603,
      "step": 780
    },
    {
      "epoch": 1.2026666666666666,
      "grad_norm": 2.4630556106567383,
      "learning_rate": 1.3303218520609827e-05,
      "loss": 0.2644,
      "step": 790
    },
    {
      "epoch": 1.2179047619047618,
      "grad_norm": 2.4921555519104004,
      "learning_rate": 1.3190287972896669e-05,
      "loss": 0.2755,
      "step": 800
    },
    {
      "epoch": 1.233142857142857,
      "grad_norm": 1.125156283378601,
      "learning_rate": 1.3077357425183513e-05,
      "loss": 0.2128,
      "step": 810
    },
    {
      "epoch": 1.2483809523809524,
      "grad_norm": 1.0967882871627808,
      "learning_rate": 1.2964426877470358e-05,
      "loss": 0.2366,
      "step": 820
    },
    {
      "epoch": 1.2636190476190476,
      "grad_norm": 1.4054702520370483,
      "learning_rate": 1.28514963297572e-05,
      "loss": 0.2432,
      "step": 830
    },
    {
      "epoch": 1.278857142857143,
      "grad_norm": 1.8749531507492065,
      "learning_rate": 1.2738565782044044e-05,
      "loss": 0.2038,
      "step": 840
    },
    {
      "epoch": 1.2940952380952382,
      "grad_norm": 1.5841875076293945,
      "learning_rate": 1.2625635234330888e-05,
      "loss": 0.189,
      "step": 850
    },
    {
      "epoch": 1.3093333333333335,
      "grad_norm": 2.4809205532073975,
      "learning_rate": 1.2512704686617732e-05,
      "loss": 0.2231,
      "step": 860
    },
    {
      "epoch": 1.3245714285714285,
      "grad_norm": 1.9062094688415527,
      "learning_rate": 1.2399774138904574e-05,
      "loss": 0.2661,
      "step": 870
    },
    {
      "epoch": 1.3398095238095238,
      "grad_norm": 2.6282129287719727,
      "learning_rate": 1.2286843591191418e-05,
      "loss": 0.2448,
      "step": 880
    },
    {
      "epoch": 1.355047619047619,
      "grad_norm": 2.381211042404175,
      "learning_rate": 1.2173913043478263e-05,
      "loss": 0.2427,
      "step": 890
    },
    {
      "epoch": 1.3702857142857143,
      "grad_norm": 1.1834970712661743,
      "learning_rate": 1.2060982495765105e-05,
      "loss": 0.2409,
      "step": 900
    },
    {
      "epoch": 1.3855238095238096,
      "grad_norm": 1.9783927202224731,
      "learning_rate": 1.1948051948051949e-05,
      "loss": 0.234,
      "step": 910
    },
    {
      "epoch": 1.4007619047619047,
      "grad_norm": 1.0290518999099731,
      "learning_rate": 1.1835121400338791e-05,
      "loss": 0.2441,
      "step": 920
    },
    {
      "epoch": 1.416,
      "grad_norm": 1.33124577999115,
      "learning_rate": 1.1722190852625637e-05,
      "loss": 0.2466,
      "step": 930
    },
    {
      "epoch": 1.4312380952380952,
      "grad_norm": 2.3671209812164307,
      "learning_rate": 1.1609260304912479e-05,
      "loss": 0.1859,
      "step": 940
    },
    {
      "epoch": 1.4464761904761905,
      "grad_norm": 3.9501566886901855,
      "learning_rate": 1.1496329757199323e-05,
      "loss": 0.2348,
      "step": 950
    },
    {
      "epoch": 1.4617142857142857,
      "grad_norm": 1.270851492881775,
      "learning_rate": 1.1383399209486168e-05,
      "loss": 0.253,
      "step": 960
    },
    {
      "epoch": 1.476952380952381,
      "grad_norm": 1.1568647623062134,
      "learning_rate": 1.127046866177301e-05,
      "loss": 0.2583,
      "step": 970
    },
    {
      "epoch": 1.4921904761904763,
      "grad_norm": 1.6539113521575928,
      "learning_rate": 1.1157538114059854e-05,
      "loss": 0.2219,
      "step": 980
    },
    {
      "epoch": 1.5074285714285716,
      "grad_norm": 1.4590109586715698,
      "learning_rate": 1.1044607566346696e-05,
      "loss": 0.2006,
      "step": 990
    },
    {
      "epoch": 1.5226666666666666,
      "grad_norm": 1.4125443696975708,
      "learning_rate": 1.0931677018633542e-05,
      "loss": 0.2254,
      "step": 1000
    },
    {
      "epoch": 1.5379047619047619,
      "grad_norm": 1.0112757682800293,
      "learning_rate": 1.0818746470920386e-05,
      "loss": 0.2118,
      "step": 1010
    },
    {
      "epoch": 1.5531428571428572,
      "grad_norm": 1.2770698070526123,
      "learning_rate": 1.0705815923207228e-05,
      "loss": 0.2671,
      "step": 1020
    },
    {
      "epoch": 1.5683809523809524,
      "grad_norm": 2.2669169902801514,
      "learning_rate": 1.0592885375494073e-05,
      "loss": 0.1929,
      "step": 1030
    },
    {
      "epoch": 1.5836190476190475,
      "grad_norm": 2.496621608734131,
      "learning_rate": 1.0479954827780915e-05,
      "loss": 0.2281,
      "step": 1040
    },
    {
      "epoch": 1.5988571428571428,
      "grad_norm": 2.113283395767212,
      "learning_rate": 1.036702428006776e-05,
      "loss": 0.1982,
      "step": 1050
    },
    {
      "epoch": 1.614095238095238,
      "grad_norm": 1.047322392463684,
      "learning_rate": 1.0254093732354601e-05,
      "loss": 0.1905,
      "step": 1060
    },
    {
      "epoch": 1.6293333333333333,
      "grad_norm": 1.765018105506897,
      "learning_rate": 1.0141163184641447e-05,
      "loss": 0.2275,
      "step": 1070
    },
    {
      "epoch": 1.6445714285714286,
      "grad_norm": 3.5516021251678467,
      "learning_rate": 1.002823263692829e-05,
      "loss": 0.1956,
      "step": 1080
    },
    {
      "epoch": 1.6598095238095238,
      "grad_norm": 1.475169062614441,
      "learning_rate": 9.915302089215133e-06,
      "loss": 0.213,
      "step": 1090
    },
    {
      "epoch": 1.6750476190476191,
      "grad_norm": 1.6291996240615845,
      "learning_rate": 9.802371541501977e-06,
      "loss": 0.1771,
      "step": 1100
    },
    {
      "epoch": 1.6902857142857144,
      "grad_norm": 0.8727717399597168,
      "learning_rate": 9.68944099378882e-06,
      "loss": 0.157,
      "step": 1110
    },
    {
      "epoch": 1.7055238095238097,
      "grad_norm": 0.9249263405799866,
      "learning_rate": 9.576510446075664e-06,
      "loss": 0.2706,
      "step": 1120
    },
    {
      "epoch": 1.7207619047619047,
      "grad_norm": 1.763485074043274,
      "learning_rate": 9.463579898362508e-06,
      "loss": 0.2151,
      "step": 1130
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.1120400428771973,
      "learning_rate": 9.350649350649352e-06,
      "loss": 0.1703,
      "step": 1140
    },
    {
      "epoch": 1.7512380952380953,
      "grad_norm": 1.0865745544433594,
      "learning_rate": 9.237718802936196e-06,
      "loss": 0.1509,
      "step": 1150
    },
    {
      "epoch": 1.7664761904761903,
      "grad_norm": 0.9319331645965576,
      "learning_rate": 9.124788255223038e-06,
      "loss": 0.1892,
      "step": 1160
    },
    {
      "epoch": 1.7817142857142856,
      "grad_norm": 4.479123592376709,
      "learning_rate": 9.011857707509882e-06,
      "loss": 0.2151,
      "step": 1170
    },
    {
      "epoch": 1.7969523809523809,
      "grad_norm": 1.8525339365005493,
      "learning_rate": 8.898927159796726e-06,
      "loss": 0.2041,
      "step": 1180
    },
    {
      "epoch": 1.8121904761904761,
      "grad_norm": 1.8500832319259644,
      "learning_rate": 8.78599661208357e-06,
      "loss": 0.1756,
      "step": 1190
    },
    {
      "epoch": 1.8274285714285714,
      "grad_norm": 1.3196920156478882,
      "learning_rate": 8.673066064370413e-06,
      "loss": 0.1831,
      "step": 1200
    },
    {
      "epoch": 1.8426666666666667,
      "grad_norm": 0.8689365386962891,
      "learning_rate": 8.560135516657257e-06,
      "loss": 0.1574,
      "step": 1210
    },
    {
      "epoch": 1.857904761904762,
      "grad_norm": 0.9500037431716919,
      "learning_rate": 8.4472049689441e-06,
      "loss": 0.2271,
      "step": 1220
    },
    {
      "epoch": 1.8731428571428572,
      "grad_norm": 1.1942447423934937,
      "learning_rate": 8.334274421230943e-06,
      "loss": 0.18,
      "step": 1230
    },
    {
      "epoch": 1.8883809523809525,
      "grad_norm": 1.007209062576294,
      "learning_rate": 8.221343873517787e-06,
      "loss": 0.2455,
      "step": 1240
    },
    {
      "epoch": 1.9036190476190478,
      "grad_norm": 0.9288345575332642,
      "learning_rate": 8.10841332580463e-06,
      "loss": 0.201,
      "step": 1250
    },
    {
      "epoch": 1.9188571428571428,
      "grad_norm": 1.0916348695755005,
      "learning_rate": 7.995482778091474e-06,
      "loss": 0.1893,
      "step": 1260
    },
    {
      "epoch": 1.934095238095238,
      "grad_norm": 1.8141506910324097,
      "learning_rate": 7.882552230378318e-06,
      "loss": 0.1862,
      "step": 1270
    },
    {
      "epoch": 1.9493333333333334,
      "grad_norm": 2.2233293056488037,
      "learning_rate": 7.769621682665162e-06,
      "loss": 0.1843,
      "step": 1280
    },
    {
      "epoch": 1.9645714285714284,
      "grad_norm": 1.135906457901001,
      "learning_rate": 7.656691134952006e-06,
      "loss": 0.2274,
      "step": 1290
    },
    {
      "epoch": 1.9798095238095237,
      "grad_norm": 1.869590163230896,
      "learning_rate": 7.543760587238849e-06,
      "loss": 0.1651,
      "step": 1300
    },
    {
      "epoch": 1.995047619047619,
      "grad_norm": 1.960608720779419,
      "learning_rate": 7.430830039525693e-06,
      "loss": 0.2283,
      "step": 1310
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9468723221936589,
      "eval_f1": 0.9443447037701975,
      "eval_loss": 0.18505674600601196,
      "eval_precision": 0.9100346020761245,
      "eval_recall": 0.9813432835820896,
      "eval_runtime": 56.0344,
      "eval_samples_per_second": 20.826,
      "eval_steps_per_second": 5.211,
      "step": 1314
    },
    {
      "epoch": 2.0091428571428573,
      "grad_norm": 0.9348922967910767,
      "learning_rate": 7.317899491812536e-06,
      "loss": 0.1647,
      "step": 1320
    },
    {
      "epoch": 2.024380952380952,
      "grad_norm": 1.8923221826553345,
      "learning_rate": 7.2049689440993795e-06,
      "loss": 0.1375,
      "step": 1330
    },
    {
      "epoch": 2.0396190476190474,
      "grad_norm": 1.6459448337554932,
      "learning_rate": 7.0920383963862224e-06,
      "loss": 0.1819,
      "step": 1340
    },
    {
      "epoch": 2.0548571428571427,
      "grad_norm": 2.7803425788879395,
      "learning_rate": 6.979107848673067e-06,
      "loss": 0.2019,
      "step": 1350
    },
    {
      "epoch": 2.070095238095238,
      "grad_norm": 2.205627679824829,
      "learning_rate": 6.86617730095991e-06,
      "loss": 0.2004,
      "step": 1360
    },
    {
      "epoch": 2.0853333333333333,
      "grad_norm": 5.355140209197998,
      "learning_rate": 6.753246753246754e-06,
      "loss": 0.2247,
      "step": 1370
    },
    {
      "epoch": 2.1005714285714285,
      "grad_norm": 2.8771114349365234,
      "learning_rate": 6.640316205533598e-06,
      "loss": 0.1482,
      "step": 1380
    },
    {
      "epoch": 2.115809523809524,
      "grad_norm": 1.174233317375183,
      "learning_rate": 6.527385657820441e-06,
      "loss": 0.2272,
      "step": 1390
    },
    {
      "epoch": 2.131047619047619,
      "grad_norm": 0.9603913426399231,
      "learning_rate": 6.414455110107285e-06,
      "loss": 0.1683,
      "step": 1400
    },
    {
      "epoch": 2.1462857142857144,
      "grad_norm": 3.877593994140625,
      "learning_rate": 6.3015245623941275e-06,
      "loss": 0.182,
      "step": 1410
    },
    {
      "epoch": 2.1615238095238096,
      "grad_norm": 1.1852855682373047,
      "learning_rate": 6.188594014680972e-06,
      "loss": 0.2685,
      "step": 1420
    },
    {
      "epoch": 2.176761904761905,
      "grad_norm": 2.2847864627838135,
      "learning_rate": 6.075663466967815e-06,
      "loss": 0.205,
      "step": 1430
    },
    {
      "epoch": 2.192,
      "grad_norm": 1.007274866104126,
      "learning_rate": 5.962732919254659e-06,
      "loss": 0.2524,
      "step": 1440
    },
    {
      "epoch": 2.2072380952380954,
      "grad_norm": 1.2216482162475586,
      "learning_rate": 5.849802371541502e-06,
      "loss": 0.1632,
      "step": 1450
    },
    {
      "epoch": 2.2224761904761903,
      "grad_norm": 1.8029271364212036,
      "learning_rate": 5.736871823828346e-06,
      "loss": 0.1294,
      "step": 1460
    },
    {
      "epoch": 2.2377142857142855,
      "grad_norm": 1.1219373941421509,
      "learning_rate": 5.62394127611519e-06,
      "loss": 0.1933,
      "step": 1470
    },
    {
      "epoch": 2.252952380952381,
      "grad_norm": 2.4540202617645264,
      "learning_rate": 5.511010728402033e-06,
      "loss": 0.2102,
      "step": 1480
    },
    {
      "epoch": 2.268190476190476,
      "grad_norm": 1.35671865940094,
      "learning_rate": 5.398080180688877e-06,
      "loss": 0.1553,
      "step": 1490
    },
    {
      "epoch": 2.2834285714285714,
      "grad_norm": 1.3565661907196045,
      "learning_rate": 5.28514963297572e-06,
      "loss": 0.139,
      "step": 1500
    },
    {
      "epoch": 2.2986666666666666,
      "grad_norm": 2.204662561416626,
      "learning_rate": 5.172219085262564e-06,
      "loss": 0.1514,
      "step": 1510
    },
    {
      "epoch": 2.313904761904762,
      "grad_norm": 0.8239237070083618,
      "learning_rate": 5.059288537549407e-06,
      "loss": 0.1705,
      "step": 1520
    },
    {
      "epoch": 2.329142857142857,
      "grad_norm": 1.1560178995132446,
      "learning_rate": 4.946357989836252e-06,
      "loss": 0.2166,
      "step": 1530
    },
    {
      "epoch": 2.3443809523809525,
      "grad_norm": 3.5407586097717285,
      "learning_rate": 4.833427442123095e-06,
      "loss": 0.1921,
      "step": 1540
    },
    {
      "epoch": 2.3596190476190477,
      "grad_norm": 1.257094383239746,
      "learning_rate": 4.7204968944099384e-06,
      "loss": 0.1682,
      "step": 1550
    },
    {
      "epoch": 2.374857142857143,
      "grad_norm": 1.2633298635482788,
      "learning_rate": 4.607566346696781e-06,
      "loss": 0.1624,
      "step": 1560
    },
    {
      "epoch": 2.3900952380952383,
      "grad_norm": 1.1612522602081299,
      "learning_rate": 4.494635798983625e-06,
      "loss": 0.1535,
      "step": 1570
    },
    {
      "epoch": 2.405333333333333,
      "grad_norm": 5.575986862182617,
      "learning_rate": 4.381705251270469e-06,
      "loss": 0.2203,
      "step": 1580
    },
    {
      "epoch": 2.420571428571429,
      "grad_norm": 0.5328029990196228,
      "learning_rate": 4.268774703557312e-06,
      "loss": 0.1354,
      "step": 1590
    },
    {
      "epoch": 2.4358095238095236,
      "grad_norm": 0.9952499270439148,
      "learning_rate": 4.155844155844157e-06,
      "loss": 0.1277,
      "step": 1600
    },
    {
      "epoch": 2.451047619047619,
      "grad_norm": 0.9397181868553162,
      "learning_rate": 4.042913608131e-06,
      "loss": 0.1887,
      "step": 1610
    },
    {
      "epoch": 2.466285714285714,
      "grad_norm": 1.0403032302856445,
      "learning_rate": 3.9299830604178435e-06,
      "loss": 0.2197,
      "step": 1620
    },
    {
      "epoch": 2.4815238095238095,
      "grad_norm": 1.827087163925171,
      "learning_rate": 3.817052512704687e-06,
      "loss": 0.2245,
      "step": 1630
    },
    {
      "epoch": 2.4967619047619047,
      "grad_norm": 0.8937751650810242,
      "learning_rate": 3.7041219649915307e-06,
      "loss": 0.1641,
      "step": 1640
    },
    {
      "epoch": 2.512,
      "grad_norm": 1.8813914060592651,
      "learning_rate": 3.591191417278374e-06,
      "loss": 0.1847,
      "step": 1650
    },
    {
      "epoch": 2.5272380952380953,
      "grad_norm": 1.2567931413650513,
      "learning_rate": 3.4782608695652175e-06,
      "loss": 0.1416,
      "step": 1660
    },
    {
      "epoch": 2.5424761904761906,
      "grad_norm": 2.5124082565307617,
      "learning_rate": 3.365330321852061e-06,
      "loss": 0.1646,
      "step": 1670
    },
    {
      "epoch": 2.557714285714286,
      "grad_norm": 2.2174417972564697,
      "learning_rate": 3.2523997741389047e-06,
      "loss": 0.2151,
      "step": 1680
    },
    {
      "epoch": 2.572952380952381,
      "grad_norm": 2.0920889377593994,
      "learning_rate": 3.1394692264257485e-06,
      "loss": 0.1772,
      "step": 1690
    },
    {
      "epoch": 2.5881904761904764,
      "grad_norm": 2.379889488220215,
      "learning_rate": 3.0265386787125924e-06,
      "loss": 0.2353,
      "step": 1700
    },
    {
      "epoch": 2.603428571428571,
      "grad_norm": 4.344366073608398,
      "learning_rate": 2.9136081309994358e-06,
      "loss": 0.2289,
      "step": 1710
    },
    {
      "epoch": 2.618666666666667,
      "grad_norm": 1.8252284526824951,
      "learning_rate": 2.800677583286279e-06,
      "loss": 0.1449,
      "step": 1720
    },
    {
      "epoch": 2.6339047619047617,
      "grad_norm": 1.924470067024231,
      "learning_rate": 2.687747035573123e-06,
      "loss": 0.1973,
      "step": 1730
    },
    {
      "epoch": 2.649142857142857,
      "grad_norm": 1.143855094909668,
      "learning_rate": 2.5748164878599664e-06,
      "loss": 0.1938,
      "step": 1740
    },
    {
      "epoch": 2.6643809523809523,
      "grad_norm": 6.907541275024414,
      "learning_rate": 2.4618859401468098e-06,
      "loss": 0.2835,
      "step": 1750
    },
    {
      "epoch": 2.6796190476190476,
      "grad_norm": 4.551443099975586,
      "learning_rate": 2.3489553924336536e-06,
      "loss": 0.2064,
      "step": 1760
    },
    {
      "epoch": 2.694857142857143,
      "grad_norm": 1.2297600507736206,
      "learning_rate": 2.236024844720497e-06,
      "loss": 0.1537,
      "step": 1770
    },
    {
      "epoch": 2.710095238095238,
      "grad_norm": 1.5597461462020874,
      "learning_rate": 2.123094297007341e-06,
      "loss": 0.1707,
      "step": 1780
    },
    {
      "epoch": 2.7253333333333334,
      "grad_norm": 1.248984694480896,
      "learning_rate": 2.0101637492941842e-06,
      "loss": 0.189,
      "step": 1790
    },
    {
      "epoch": 2.7405714285714287,
      "grad_norm": 0.8186496496200562,
      "learning_rate": 1.8972332015810276e-06,
      "loss": 0.1725,
      "step": 1800
    },
    {
      "epoch": 2.755809523809524,
      "grad_norm": 1.1983822584152222,
      "learning_rate": 1.7843026538678714e-06,
      "loss": 0.161,
      "step": 1810
    },
    {
      "epoch": 2.771047619047619,
      "grad_norm": 1.6469279527664185,
      "learning_rate": 1.671372106154715e-06,
      "loss": 0.1583,
      "step": 1820
    },
    {
      "epoch": 2.7862857142857145,
      "grad_norm": 3.6126067638397217,
      "learning_rate": 1.5584415584415584e-06,
      "loss": 0.3061,
      "step": 1830
    },
    {
      "epoch": 2.8015238095238093,
      "grad_norm": 0.8975072503089905,
      "learning_rate": 1.445511010728402e-06,
      "loss": 0.1708,
      "step": 1840
    },
    {
      "epoch": 2.816761904761905,
      "grad_norm": 1.066812515258789,
      "learning_rate": 1.3325804630152459e-06,
      "loss": 0.1557,
      "step": 1850
    },
    {
      "epoch": 2.832,
      "grad_norm": 1.9394052028656006,
      "learning_rate": 1.2196499153020893e-06,
      "loss": 0.1928,
      "step": 1860
    },
    {
      "epoch": 2.847238095238095,
      "grad_norm": 1.2912248373031616,
      "learning_rate": 1.1067193675889329e-06,
      "loss": 0.1808,
      "step": 1870
    },
    {
      "epoch": 2.8624761904761904,
      "grad_norm": 3.7547266483306885,
      "learning_rate": 9.937888198757765e-07,
      "loss": 0.1623,
      "step": 1880
    },
    {
      "epoch": 2.8777142857142857,
      "grad_norm": 1.7413266897201538,
      "learning_rate": 8.808582721626201e-07,
      "loss": 0.2096,
      "step": 1890
    },
    {
      "epoch": 2.892952380952381,
      "grad_norm": 1.223198413848877,
      "learning_rate": 7.679277244494636e-07,
      "loss": 0.1394,
      "step": 1900
    },
    {
      "epoch": 2.908190476190476,
      "grad_norm": 2.2741811275482178,
      "learning_rate": 6.549971767363072e-07,
      "loss": 0.1957,
      "step": 1910
    },
    {
      "epoch": 2.9234285714285715,
      "grad_norm": 0.7960083484649658,
      "learning_rate": 5.420666290231508e-07,
      "loss": 0.2094,
      "step": 1920
    },
    {
      "epoch": 2.9386666666666668,
      "grad_norm": 1.743585228919983,
      "learning_rate": 4.291360813099944e-07,
      "loss": 0.2655,
      "step": 1930
    },
    {
      "epoch": 2.953904761904762,
      "grad_norm": 1.400397777557373,
      "learning_rate": 3.1620553359683794e-07,
      "loss": 0.1357,
      "step": 1940
    },
    {
      "epoch": 2.9691428571428573,
      "grad_norm": 3.4769678115844727,
      "learning_rate": 2.0327498588368155e-07,
      "loss": 0.1352,
      "step": 1950
    },
    {
      "epoch": 2.9843809523809526,
      "grad_norm": 1.3718507289886475,
      "learning_rate": 9.034443817052513e-08,
      "loss": 0.2133,
      "step": 1960
    },
    {
      "epoch": 2.9965714285714284,
      "eval_accuracy": 0.9468723221936589,
      "eval_f1": 0.9442446043165468,
      "eval_loss": 0.17484153807163239,
      "eval_precision": 0.9114583333333334,
      "eval_recall": 0.9794776119402985,
      "eval_runtime": 55.9786,
      "eval_samples_per_second": 20.847,
      "eval_steps_per_second": 5.216,
      "step": 1968
    }
  ],
  "logging_steps": 10,
  "max_steps": 1968,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.788048155331789e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
